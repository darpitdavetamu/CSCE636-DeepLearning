{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE636_Project_Submission10_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgRFcuXTM49z",
        "outputId": "b729859c-b2cd-4fed-8a4b-507d63a4ee9e"
      },
      "source": [
        "#to call all the time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from keras.layers import Conv1D, MaxPooling1D, Activation\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "import json\n",
        "import glob\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "# For mouting Google drive to be used for data\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0yht2XxSSmL"
      },
      "source": [
        "def convert_data(start, stop, folder_name_json, file_name_text):\n",
        "  '''\n",
        "  start- starting of the video number to be added to text file\n",
        "  stop - last video number to be added\n",
        "  folder_name_json - path of json files for videos\n",
        "  file_name_text -  path of text file where the key-point values are to stored\n",
        "  '''\n",
        "  with open(file_name_text,\"w\") as x:\n",
        "    for i in range(start, stop+1):\n",
        "          json_files = glob.glob(folder_name_json + '/'+ str(i)+\"/*\")\n",
        "          j=0\n",
        "          for jfile in json_files:\n",
        "            if j< 140:\n",
        "              j = j + 1\n",
        "              with open(jfile) as f:\n",
        "                  data = json.load(f)\n",
        "                  if data['people']:\n",
        "                      kp= data['people'][0]['pose_keypoints_2d']\n",
        "                      kp = [ str(v) for v in kp]\n",
        "                      r =','.join(kp)\n",
        "                      x.write('{}\\n'.format(r))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWURrvOzSUA5"
      },
      "source": [
        "def read_data(file_name):\n",
        "  '''\n",
        "  INPUT: file_name = text file which is to be converted ito array\n",
        "  OUTPUT: data = return the array\n",
        "  '''\n",
        "  number = [i for i in range(0, 74) if (i+1) % 3 != 0]\n",
        "  data = np.loadtxt(file_name, usecols=number, delimiter = \",\")\n",
        "  return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0jKUQpSVTB"
      },
      "source": [
        "def generate_label():\n",
        "  '''\n",
        "  OUTPUT: Ytrain - labels for training data\n",
        "          Yval - labels for validation data\n",
        "  '''\n",
        "  y = np.zeros(60)\n",
        "  y = np.append(y, np.ones(80))        #1\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #2\n",
        "  y = np.append(y, np.zeros(80))\n",
        "  y = np.append(y, np.ones(60))        #3\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #4\n",
        "  y = np.append(y, np.zeros(40))\n",
        "  y = np.append(y, np.ones(100))       #5\n",
        "  y = np.append(y, np.zeros(60))     \n",
        "  y = np.append(y, np.ones(80))        #6\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #7\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #8\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #9\n",
        "  y = np.append(y, np.zeros(60)) \n",
        "  y = np.append(y, np.ones(80))        #10\n",
        "  y = np.append(y, np.zeros(30)) \n",
        "  y = np.append(y, np.ones(110))       #11\n",
        "  y = np.append(y, np.zeros(60)) \n",
        "  y = np.append(y, np.ones(80))        #12\n",
        "  y = np.append(y, np.zeros(2520))     #30\n",
        "  y = np.append(y, np.zeros(90))\n",
        "  y = np.append(y, np.ones(50))        #31\n",
        "  y = np.append(y, np.zeros(40))\n",
        "  y = np.append(y, np.ones(100))       #32\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #33\n",
        "  y = np.append(y, np.zeros(30)) \n",
        "  y = np.append(y, np.ones(110))       #34\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #35\n",
        "  y = np.append(y, np.zeros(30)) \n",
        "  y = np.append(y, np.ones(110))       #36\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #37\n",
        "  y = np.append(y, np.zeros(60)) \n",
        "  y = np.append(y, np.ones(80))        #38\n",
        "  y = np.append(y, np.zeros(80))\n",
        "  y = np.append(y, np.ones(60))        #39\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #40\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #41\n",
        "  y = np.append(y, np.ones(700))       #46\n",
        "  y = np.append(y, np.zeros(420))      #49   \n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #50\n",
        "  y = np.append(y, np.zeros(420))      #53\n",
        "  y = np.append(y, np.ones(840))       #59\n",
        "  y = np.append(y, np.zeros(3500))     #84\n",
        "  y = np.append(y, np.ones(840))       #90\n",
        "  y = np.append(y, np.zeros(40))\n",
        "  y = np.append(y, np.ones(100))       #91\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #92\n",
        "  y = np.append(y, np.zeros(70))\n",
        "  y = np.append(y, np.ones(70))        #93\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #94\n",
        "  y = np.append(y, np.zeros(40)) \n",
        "  y = np.append(y, np.ones(100))       #95\n",
        "  y = np.append(y, np.zeros(60))\n",
        "  y = np.append(y, np.ones(80))        #96\n",
        "  y = np.append(y, np.zeros(50)) \n",
        "  y = np.append(y, np.ones(90))        #97\n",
        "  y = np.append(y, np.zeros(30)) \n",
        "  y = np.append(y, np.ones(110))       #98\n",
        "  y = np.append(y, np.zeros(110))\n",
        "  y = np.append(y, np.ones(30))        #99\n",
        "  y = np.append(y, np.zeros(30))\n",
        "  y = np.append(y, np.ones(110))       #100\n",
        "  y = np.append(y, np.zeros(1260))       #109\n",
        "  y = np.append(y, np.ones(1260))       #118\n",
        "  y = np.append(y, np.zeros(2800))       #138\n",
        "  y = np.append(y, np.ones(3080))       #160\n",
        "\n",
        "  Ytrain = np.concatenate((y[:9800], y[16520:22400]), axis=0)\n",
        "  Yval = y[9800:16520]\n",
        "\n",
        "  return Ytrain,Yval"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rIyXY6WTHlF",
        "outputId": "c76d73b9-27f7-40b9-ecb7-172670e47bd1"
      },
      "source": [
        "#GENERATING TRAINING AND VALIDATION ARRAYS:\n",
        "\n",
        "#FOR X-file:\n",
        "file_name_train = \"/content/drive/My Drive/CSCE636/Train_Val_Test/X_train.txt\"   ##CHANGE accordingly while increasing dataset##\n",
        "Xtrain = read_data(file_name_train) \n",
        "file_name_train1 = \"/content/drive/My Drive/CSCE636/Train_Val_Test/X_train_new.txt\"   ##CHANGE accordingly while increasing dataset##\n",
        "Xtrain_new = read_data(file_name_train1)\n",
        "Xtrain = np.concatenate((Xtrain, Xtrain_new), axis=0)\n",
        "Xtrain = Xtrain.reshape(1568,10,50) \n",
        "\n",
        "file_name_val = \"/content/drive/My Drive/CSCE636/Train_Val_Test/X_val.txt\"   ##CHANGE accordingly while increasing dataset##\n",
        "Xval = read_data(file_name_val) \n",
        "file_name_val1 = \"/content/drive/My Drive/CSCE636/Train_Val_Test/X_Val_new.txt\"   ##CHANGE accordingly while increasing dataset##\n",
        "Xval_new = read_data(file_name_val1)\n",
        "Xval = np.concatenate((Xval, Xval_new), axis=0)\n",
        "Xval = Xval.reshape(672,10,50)\n",
        "\n",
        "#FOR Y-file:\n",
        "Ytrain,Yval = generate_label()\n",
        "Ytrain = Ytrain.reshape(1568,10,1)\n",
        "Yval = Yval.reshape(672,10,1)\n",
        "\n",
        "print('X-training = ', Xtrain.shape)\n",
        "print('X-validation = ',Xval.shape)\n",
        "print('Y-training = ', Ytrain.shape)\n",
        "print('Y-validation = ',Yval.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X-training =  (1568, 10, 50)\n",
            "X-validation =  (672, 10, 50)\n",
            "Y-training =  (1568, 10, 1)\n",
            "Y-validation =  (672, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAQq_6bt64Si"
      },
      "source": [
        "# Setting up early stopping criteria\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "path1 = '/content/drive/My Drive/CSCE636/Model/Submission10_1/model_submit10_model1_epochs.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "path2 = '/content/drive/My Drive/CSCE636/Model/Submission10_2/model_submit10_model2_epochs.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "path3 = '/content/drive/My Drive/CSCE636/Model/Submission10_3/model_submit10_model3_epochs.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "path4 = '/content/drive/My Drive/CSCE636/Model/Submission10_4/model_submit10_model4_epochs.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save1 = ModelCheckpoint(path1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "mcp_save2 = ModelCheckpoint(path2, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "mcp_save3 = ModelCheckpoint(path3, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "mcp_save4 = ModelCheckpoint(path4, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min')\n",
        "\n",
        "checkpoint1 = [earlyStopping, mcp_save1, reduce_lr_loss]\n",
        "checkpoint2 = [earlyStopping, mcp_save2, reduce_lr_loss]\n",
        "checkpoint3 = [earlyStopping, mcp_save3, reduce_lr_loss]\n",
        "checkpoint4 = [earlyStopping, mcp_save4, reduce_lr_loss]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3wAdzm5_Rhr",
        "outputId": "b0bf1a0d-61c5-4ce9-b200-c7c048cd1ee7"
      },
      "source": [
        "  ###DATA AUGMENTATION###\n",
        "A = np.random.normal(0.0, 10.0, (1568,10,50) )\n",
        "Xtrain_noise = np.add(Xtrain , A)\n",
        "Xtrain = np.concatenate((Xtrain,Xtrain_noise), axis=0)\n",
        "print('X-training shape after adding noise = ' , Xtrain.shape)\n",
        "\n",
        "Ytrain = np.concatenate((Ytrain,Ytrain), axis=0)\n",
        "print('Y-training shape after adding noise = ' , Ytrain.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X-training shape after adding noise =  (3136, 10, 50)\n",
            "Y-training shape after adding noise =  (3136, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw0HDbsVm7rp",
        "outputId": "b0bda2cd-4b5e-440b-def1-bcee5c144592"
      },
      "source": [
        "print('X-validation shape after adding noise = ' , Xval.shape)\n",
        "print('Y-validation shape after adding noise = ' , Yval.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X-validation shape after adding noise =  (672, 10, 50)\n",
            "Y-validation shape after adding noise =  (672, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn7ntNSShVZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dd4607-6f5d-4d21-d3c7-48247a4dd5f9"
      },
      "source": [
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model1.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model1.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "model1.add(tf.keras.layers.LSTM(500, return_sequences=True))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid')))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.0001)\n",
        "model1.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model1.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 10, 500)           1102000   \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 10, 32)            16032     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 10, 1)             33        \n",
            "=================================================================\n",
            "Total params: 7,124,065\n",
            "Trainable params: 7,124,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwaLnnKgYtb",
        "outputId": "4b2222ac-c4c6-4e55-f106-fbe594d899a3"
      },
      "source": [
        "#Main model\n",
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model2.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True)))\n",
        "model2.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model2.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True)))\n",
        "model2.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model2.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "model2.add(tf.keras.layers.LSTM(500, return_sequences=True))\n",
        "model2.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "model2.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid')))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.0001)\n",
        "model2.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model2.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 10, 500)           1102000   \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 1000)          4004000   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 10, 500)           3002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 10, 1000)          4004000   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 10, 500)           3002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 10, 32)            16032     \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 10, 1)             33        \n",
            "=================================================================\n",
            "Total params: 17,132,065\n",
            "Trainable params: 17,132,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQE1QeWSguXs",
        "outputId": "92c48edd-f1da-4ee5-a3da-6a5514627ed6"
      },
      "source": [
        "#Main model\n",
        "model3 = tf.keras.models.Sequential()\n",
        "model3.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model3.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model3.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model3.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model3.add(tf.keras.layers.Conv1D(500, kernel_size=2, strides=1,activation='relu',input_shape=(10,50), padding='same'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "model3.add(tf.keras.layers.LSTM(500, return_sequences=True))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "model3.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid')))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.0001)\n",
        "model3.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model3.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, 10, 500)           1102000   \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 10, 500)           500500    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 10, 32)            16032     \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 10, 1)             33        \n",
            "=================================================================\n",
            "Total params: 7,630,565\n",
            "Trainable params: 7,627,565\n",
            "Non-trainable params: 3,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKXkJobeg1oh",
        "outputId": "ef8517ca-2115-43ba-f1e5-218f110f01f5"
      },
      "source": [
        "model4 = tf.keras.models.Sequential()\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2)))\n",
        "model4.add(tf.keras.layers.Conv1D(500, kernel_size=2, strides=1,activation='relu',input_shape=(10,50), padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(tf.keras.layers.LSTM(500, input_shape=(10,50), return_sequences=True))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "model4.add(tf.keras.layers.LSTM(500, return_sequences=True))\n",
        "model4.add(tf.keras.layers.LSTM(500, return_sequences=True))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "model4.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid')))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.0001)\n",
        "model4.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model4.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_14 (LSTM)               (None, 10, 500)           1102000   \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "time_distributed_16 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 10, 500)           500500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "time_distributed_17 (TimeDis (None, 10, 500)           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 10, 500)           2002000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10, 500)           2000      \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 10, 32)            16032     \n",
            "_________________________________________________________________\n",
            "time_distributed_19 (TimeDis (None, 10, 1)             33        \n",
            "=================================================================\n",
            "Total params: 15,638,565\n",
            "Trainable params: 15,635,565\n",
            "Non-trainable params: 3,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq7cQ-71NXCO",
        "outputId": "a55650b6-072f-45ac-cfc7-731bcfe1ea01"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "history1 = model1.fit(Xtrain, Ytrain, batch_size =100, epochs = 500, verbose = 1, validation_data=(Xval, Yval),callbacks=checkpoint1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 22s 58ms/step - loss: 1.2340 - accuracy: 0.6398 - val_loss: 1.1255 - val_accuracy: 0.7552\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.0230 - accuracy: 0.8132 - val_loss: 0.9679 - val_accuracy: 0.8083\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.9249 - accuracy: 0.8372 - val_loss: 0.8943 - val_accuracy: 0.8412\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.8434 - accuracy: 0.8689 - val_loss: 0.8248 - val_accuracy: 0.8493\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.7575 - accuracy: 0.8909 - val_loss: 0.7795 - val_accuracy: 0.8750\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.7162 - accuracy: 0.8894 - val_loss: 0.7610 - val_accuracy: 0.8661\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6674 - accuracy: 0.8919 - val_loss: 0.7100 - val_accuracy: 0.8699\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6425 - accuracy: 0.8921 - val_loss: 0.6824 - val_accuracy: 0.8743\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5809 - accuracy: 0.9053 - val_loss: 0.6541 - val_accuracy: 0.8622\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.9035 - val_loss: 0.6110 - val_accuracy: 0.8689\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.8946 - val_loss: 0.5681 - val_accuracy: 0.8786\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5209 - accuracy: 0.9063 - val_loss: 0.5718 - val_accuracy: 0.8582\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4856 - accuracy: 0.9087 - val_loss: 0.5149 - val_accuracy: 0.8936\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4507 - accuracy: 0.9240 - val_loss: 0.5327 - val_accuracy: 0.8804\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.4347 - accuracy: 0.9182 - val_loss: 0.4925 - val_accuracy: 0.8978\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4103 - accuracy: 0.9224 - val_loss: 0.5725 - val_accuracy: 0.8661\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.9094 - val_loss: 0.4717 - val_accuracy: 0.8954\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4013 - accuracy: 0.9125 - val_loss: 0.5467 - val_accuracy: 0.8693\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3999 - accuracy: 0.9050 - val_loss: 0.4856 - val_accuracy: 0.8749\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.9114 - val_loss: 0.4285 - val_accuracy: 0.9012\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.3533 - accuracy: 0.9220 - val_loss: 0.4521 - val_accuracy: 0.8802\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.3524 - accuracy: 0.9202 - val_loss: 0.4657 - val_accuracy: 0.8719\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.9028 - val_loss: 0.4192 - val_accuracy: 0.8778\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3450 - accuracy: 0.9145 - val_loss: 0.4491 - val_accuracy: 0.8649\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3480 - accuracy: 0.9141 - val_loss: 0.4412 - val_accuracy: 0.8740\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2993 - accuracy: 0.9236 - val_loss: 0.3876 - val_accuracy: 0.8795\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2953 - accuracy: 0.9255 - val_loss: 0.3726 - val_accuracy: 0.8939\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3013 - accuracy: 0.9183 - val_loss: 0.4503 - val_accuracy: 0.8854\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2893 - accuracy: 0.9211 - val_loss: 0.3673 - val_accuracy: 0.9025\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2702 - accuracy: 0.9331 - val_loss: 0.3713 - val_accuracy: 0.8923\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.9300 - val_loss: 0.3623 - val_accuracy: 0.8879\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2622 - accuracy: 0.9276 - val_loss: 0.3339 - val_accuracy: 0.8936\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2395 - accuracy: 0.9363 - val_loss: 0.4017 - val_accuracy: 0.8746\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.9309 - val_loss: 0.3648 - val_accuracy: 0.9003\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2397 - accuracy: 0.9289 - val_loss: 0.3035 - val_accuracy: 0.9067\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2361 - accuracy: 0.9316 - val_loss: 0.3352 - val_accuracy: 0.8900\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2343 - accuracy: 0.9336 - val_loss: 0.3961 - val_accuracy: 0.8731\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2560 - accuracy: 0.9213 - val_loss: 0.3361 - val_accuracy: 0.8851\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.4164 - val_accuracy: 0.8740\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2418 - accuracy: 0.9250 - val_loss: 0.3637 - val_accuracy: 0.8975\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2165 - accuracy: 0.9360 - val_loss: 0.3795 - val_accuracy: 0.8778\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2395 - accuracy: 0.9228 - val_loss: 0.3305 - val_accuracy: 0.8833\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1978 - accuracy: 0.9379 - val_loss: 0.3845 - val_accuracy: 0.8836\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2013 - accuracy: 0.9397 - val_loss: 0.3812 - val_accuracy: 0.8879\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2217 - accuracy: 0.9317 - val_loss: 0.2947 - val_accuracy: 0.9109\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2030 - accuracy: 0.9366 - val_loss: 0.3256 - val_accuracy: 0.8988\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2083 - accuracy: 0.9335 - val_loss: 0.3244 - val_accuracy: 0.8805\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2020 - accuracy: 0.9394 - val_loss: 0.3518 - val_accuracy: 0.8820\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2291 - accuracy: 0.9217 - val_loss: 0.2967 - val_accuracy: 0.9027\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1920 - accuracy: 0.9414 - val_loss: 0.3051 - val_accuracy: 0.8988\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2031 - accuracy: 0.9335 - val_loss: 0.3542 - val_accuracy: 0.8961\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2139 - accuracy: 0.9290 - val_loss: 0.3510 - val_accuracy: 0.8802\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2010 - accuracy: 0.9333 - val_loss: 0.3652 - val_accuracy: 0.8875\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9341 - val_loss: 0.3294 - val_accuracy: 0.8915\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1945 - accuracy: 0.9358 - val_loss: 0.3519 - val_accuracy: 0.8902\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1816 - accuracy: 0.9423 - val_loss: 0.3453 - val_accuracy: 0.8969\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1748 - accuracy: 0.9456 - val_loss: 0.2818 - val_accuracy: 0.9241\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1763 - accuracy: 0.9438 - val_loss: 0.3320 - val_accuracy: 0.8894\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2012 - accuracy: 0.9333 - val_loss: 0.3060 - val_accuracy: 0.8854\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1884 - accuracy: 0.9348 - val_loss: 0.3133 - val_accuracy: 0.8966\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1872 - accuracy: 0.9356 - val_loss: 0.2882 - val_accuracy: 0.9110\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1800 - accuracy: 0.9391 - val_loss: 0.3157 - val_accuracy: 0.8933\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1901 - accuracy: 0.9357 - val_loss: 0.2767 - val_accuracy: 0.8987\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1949 - accuracy: 0.9318 - val_loss: 0.3668 - val_accuracy: 0.8710\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1942 - accuracy: 0.9314 - val_loss: 0.3004 - val_accuracy: 0.8991\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1641 - accuracy: 0.9430 - val_loss: 0.3113 - val_accuracy: 0.8999\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1707 - accuracy: 0.9419 - val_loss: 0.3339 - val_accuracy: 0.8988\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1690 - accuracy: 0.9417 - val_loss: 0.3203 - val_accuracy: 0.8868\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1929 - accuracy: 0.9317 - val_loss: 0.3636 - val_accuracy: 0.8826\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1711 - accuracy: 0.9427 - val_loss: 0.3534 - val_accuracy: 0.8854\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1714 - accuracy: 0.9436 - val_loss: 0.3173 - val_accuracy: 0.9024\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1712 - accuracy: 0.9413 - val_loss: 0.3066 - val_accuracy: 0.9012\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1637 - accuracy: 0.9429 - val_loss: 0.3164 - val_accuracy: 0.9040\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1656 - accuracy: 0.9434 - val_loss: 0.3062 - val_accuracy: 0.9067\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1848 - accuracy: 0.9370 - val_loss: 0.3602 - val_accuracy: 0.8833\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1784 - accuracy: 0.9420 - val_loss: 0.3416 - val_accuracy: 0.9019\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1649 - accuracy: 0.9404 - val_loss: 0.3155 - val_accuracy: 0.8933\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1650 - accuracy: 0.9427 - val_loss: 0.2905 - val_accuracy: 0.9042\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1489 - accuracy: 0.9527 - val_loss: 0.2963 - val_accuracy: 0.8964\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1494 - accuracy: 0.9499 - val_loss: 0.3159 - val_accuracy: 0.8949\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1497 - accuracy: 0.9460 - val_loss: 0.3497 - val_accuracy: 0.8884\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.9466 - val_loss: 0.3173 - val_accuracy: 0.9007\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1305 - accuracy: 0.9554 - val_loss: 0.3407 - val_accuracy: 0.8929\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1856 - accuracy: 0.9301 - val_loss: 0.3314 - val_accuracy: 0.8826\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1479 - accuracy: 0.9508 - val_loss: 0.3477 - val_accuracy: 0.8939\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.9529 - val_loss: 0.3879 - val_accuracy: 0.8900\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1454 - accuracy: 0.9468 - val_loss: 0.4055 - val_accuracy: 0.8850\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1927 - accuracy: 0.9294 - val_loss: 0.3594 - val_accuracy: 0.8966\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1737 - accuracy: 0.9369 - val_loss: 0.2897 - val_accuracy: 0.9015\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1704 - accuracy: 0.9393 - val_loss: 0.3602 - val_accuracy: 0.8775\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9307 - val_loss: 0.3002 - val_accuracy: 0.9125\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1597 - accuracy: 0.9438 - val_loss: 0.3170 - val_accuracy: 0.8961\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1722 - accuracy: 0.9375 - val_loss: 0.3443 - val_accuracy: 0.8775\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1799 - accuracy: 0.9371 - val_loss: 0.3036 - val_accuracy: 0.8958\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1892 - accuracy: 0.9256 - val_loss: 0.2826 - val_accuracy: 0.8958\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1709 - accuracy: 0.9360 - val_loss: 0.2779 - val_accuracy: 0.9122\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1666 - accuracy: 0.9437 - val_loss: 0.2641 - val_accuracy: 0.9211\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.1562 - accuracy: 0.9455 - val_loss: 0.2720 - val_accuracy: 0.9110\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1532 - accuracy: 0.9444 - val_loss: 0.2620 - val_accuracy: 0.9125\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1490 - accuracy: 0.9464 - val_loss: 0.2897 - val_accuracy: 0.9064\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1467 - accuracy: 0.9474 - val_loss: 0.2765 - val_accuracy: 0.9049\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.9354 - val_loss: 0.2711 - val_accuracy: 0.9082\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1570 - accuracy: 0.9417 - val_loss: 0.2762 - val_accuracy: 0.9079\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1676 - accuracy: 0.9388 - val_loss: 0.2639 - val_accuracy: 0.9067\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1758 - accuracy: 0.9383 - val_loss: 0.2860 - val_accuracy: 0.8926\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1409 - accuracy: 0.9504 - val_loss: 0.2620 - val_accuracy: 0.9088\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1530 - accuracy: 0.9444 - val_loss: 0.3386 - val_accuracy: 0.8899\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1457 - accuracy: 0.9463 - val_loss: 0.2922 - val_accuracy: 0.9128\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1334 - accuracy: 0.9497 - val_loss: 0.2752 - val_accuracy: 0.9158\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.9535 - val_loss: 0.2533 - val_accuracy: 0.9182\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1340 - accuracy: 0.9550 - val_loss: 0.2744 - val_accuracy: 0.9106\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1557 - accuracy: 0.9433 - val_loss: 0.2835 - val_accuracy: 0.9001\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1376 - accuracy: 0.9525 - val_loss: 0.3171 - val_accuracy: 0.8972\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1392 - accuracy: 0.9496 - val_loss: 0.2531 - val_accuracy: 0.9037\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1398 - accuracy: 0.9477 - val_loss: 0.2774 - val_accuracy: 0.9122\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1252 - accuracy: 0.9539 - val_loss: 0.2711 - val_accuracy: 0.9176\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.2395 - val_accuracy: 0.9249\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1489 - accuracy: 0.9459 - val_loss: 0.3136 - val_accuracy: 0.9018\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1442 - accuracy: 0.9498 - val_loss: 0.2963 - val_accuracy: 0.9071\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1283 - accuracy: 0.9540 - val_loss: 0.2369 - val_accuracy: 0.9304\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9540 - val_loss: 0.2834 - val_accuracy: 0.9009\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1319 - accuracy: 0.9530 - val_loss: 0.2673 - val_accuracy: 0.9054\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9451 - val_loss: 0.2948 - val_accuracy: 0.9196\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1368 - accuracy: 0.9469 - val_loss: 0.2546 - val_accuracy: 0.9190\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1403 - accuracy: 0.9495 - val_loss: 0.3497 - val_accuracy: 0.8936\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1571 - accuracy: 0.9419 - val_loss: 0.2896 - val_accuracy: 0.9036\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1327 - accuracy: 0.9519 - val_loss: 0.2955 - val_accuracy: 0.9015\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1525 - accuracy: 0.9426 - val_loss: 0.2119 - val_accuracy: 0.9320\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1442 - accuracy: 0.9480 - val_loss: 0.2768 - val_accuracy: 0.8967\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1549 - accuracy: 0.9393 - val_loss: 0.2275 - val_accuracy: 0.9311\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1313 - accuracy: 0.9533 - val_loss: 0.2279 - val_accuracy: 0.9338\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1298 - accuracy: 0.9545 - val_loss: 0.2567 - val_accuracy: 0.9235\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1311 - accuracy: 0.9514 - val_loss: 0.2540 - val_accuracy: 0.9141\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9450 - val_loss: 0.3226 - val_accuracy: 0.8938\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1368 - accuracy: 0.9499 - val_loss: 0.2161 - val_accuracy: 0.9253\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1347 - accuracy: 0.9523 - val_loss: 0.2521 - val_accuracy: 0.9138\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 0.9473 - val_loss: 0.2624 - val_accuracy: 0.9185\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1166 - accuracy: 0.9570 - val_loss: 0.3046 - val_accuracy: 0.9061\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1304 - accuracy: 0.9529 - val_loss: 0.2417 - val_accuracy: 0.9277\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1213 - accuracy: 0.9568 - val_loss: 0.2807 - val_accuracy: 0.9113\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1349 - accuracy: 0.9480 - val_loss: 0.3012 - val_accuracy: 0.9091\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1362 - accuracy: 0.9508 - val_loss: 0.2480 - val_accuracy: 0.9247\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1208 - accuracy: 0.9553 - val_loss: 0.2981 - val_accuracy: 0.9095\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1102 - accuracy: 0.9596 - val_loss: 0.2855 - val_accuracy: 0.9223\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1142 - accuracy: 0.9582 - val_loss: 0.2385 - val_accuracy: 0.9229\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1398 - accuracy: 0.9509 - val_loss: 0.3047 - val_accuracy: 0.9094\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1383 - accuracy: 0.9500 - val_loss: 0.2321 - val_accuracy: 0.9302\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1294 - accuracy: 0.9528 - val_loss: 0.2619 - val_accuracy: 0.9153\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1355 - accuracy: 0.9487 - val_loss: 0.3204 - val_accuracy: 0.8975\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1217 - accuracy: 0.9526 - val_loss: 0.3153 - val_accuracy: 0.9007\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.9585 - val_loss: 0.2724 - val_accuracy: 0.9202\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1281 - accuracy: 0.9525 - val_loss: 0.3063 - val_accuracy: 0.9110\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.3009 - val_accuracy: 0.9144\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1067 - accuracy: 0.9618 - val_loss: 0.3076 - val_accuracy: 0.9073\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1222 - accuracy: 0.9551 - val_loss: 0.2868 - val_accuracy: 0.9104\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9489 - val_loss: 0.3024 - val_accuracy: 0.9153\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1526 - accuracy: 0.9448 - val_loss: 0.2655 - val_accuracy: 0.9225\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1243 - accuracy: 0.9526 - val_loss: 0.2496 - val_accuracy: 0.9277\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1226 - accuracy: 0.9558 - val_loss: 0.3022 - val_accuracy: 0.8991\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1303 - accuracy: 0.9546 - val_loss: 0.2903 - val_accuracy: 0.9125\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1275 - accuracy: 0.9516 - val_loss: 0.2825 - val_accuracy: 0.9115\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1234 - accuracy: 0.9541 - val_loss: 0.2550 - val_accuracy: 0.9234\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9505 - val_loss: 0.2834 - val_accuracy: 0.9089\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.9581 - val_loss: 0.2895 - val_accuracy: 0.9064\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1164 - accuracy: 0.9572 - val_loss: 0.2709 - val_accuracy: 0.9001\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1313 - accuracy: 0.9480 - val_loss: 0.2700 - val_accuracy: 0.9152\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1041 - accuracy: 0.9630 - val_loss: 0.2678 - val_accuracy: 0.9210\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1134 - accuracy: 0.9562 - val_loss: 0.2587 - val_accuracy: 0.9214\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.9531 - val_loss: 0.2832 - val_accuracy: 0.9110\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1332 - accuracy: 0.9484 - val_loss: 0.3045 - val_accuracy: 0.9021\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1394 - accuracy: 0.9472 - val_loss: 0.2793 - val_accuracy: 0.9199\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1319 - accuracy: 0.9519 - val_loss: 0.2813 - val_accuracy: 0.9058\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1255 - accuracy: 0.9539 - val_loss: 0.2293 - val_accuracy: 0.9260\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1042 - accuracy: 0.9632 - val_loss: 0.2349 - val_accuracy: 0.9251\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9601 - val_loss: 0.2584 - val_accuracy: 0.9193\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.9533 - val_loss: 0.2750 - val_accuracy: 0.9195\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1320 - accuracy: 0.9492 - val_loss: 0.2519 - val_accuracy: 0.9253\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1215 - accuracy: 0.9570 - val_loss: 0.2586 - val_accuracy: 0.9222\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1233 - accuracy: 0.9524 - val_loss: 0.2815 - val_accuracy: 0.9198\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1215 - accuracy: 0.9552 - val_loss: 0.2655 - val_accuracy: 0.9129\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1114 - accuracy: 0.9587 - val_loss: 0.2837 - val_accuracy: 0.9064\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1070 - accuracy: 0.9617 - val_loss: 0.2965 - val_accuracy: 0.8961\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1132 - accuracy: 0.9564 - val_loss: 0.2730 - val_accuracy: 0.9211\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.3079 - val_accuracy: 0.9229\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1033 - accuracy: 0.9641 - val_loss: 0.3614 - val_accuracy: 0.9058\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1242 - accuracy: 0.9515 - val_loss: 0.2843 - val_accuracy: 0.9171\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1166 - accuracy: 0.9565 - val_loss: 0.2848 - val_accuracy: 0.8999\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1210 - accuracy: 0.9537 - val_loss: 0.3182 - val_accuracy: 0.9051\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1324 - accuracy: 0.9525 - val_loss: 0.2754 - val_accuracy: 0.9085\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9563 - val_loss: 0.2608 - val_accuracy: 0.9216\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1192 - accuracy: 0.9546 - val_loss: 0.2944 - val_accuracy: 0.8996\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1254 - accuracy: 0.9513 - val_loss: 0.2832 - val_accuracy: 0.9018\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1285 - accuracy: 0.9539 - val_loss: 0.3049 - val_accuracy: 0.8964\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1066 - accuracy: 0.9588 - val_loss: 0.2837 - val_accuracy: 0.9183\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9609 - val_loss: 0.2546 - val_accuracy: 0.9159\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0991 - accuracy: 0.9631 - val_loss: 0.2670 - val_accuracy: 0.9094\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1000 - accuracy: 0.9645 - val_loss: 0.2450 - val_accuracy: 0.9134\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1195 - accuracy: 0.9536 - val_loss: 0.3372 - val_accuracy: 0.8905\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1344 - accuracy: 0.9516 - val_loss: 0.3239 - val_accuracy: 0.8996\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1079 - accuracy: 0.9589 - val_loss: 0.2784 - val_accuracy: 0.9144\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1203 - accuracy: 0.9555 - val_loss: 0.2823 - val_accuracy: 0.9115\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1421 - accuracy: 0.9467 - val_loss: 0.2487 - val_accuracy: 0.9150\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9545 - val_loss: 0.2741 - val_accuracy: 0.9037\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1157 - accuracy: 0.9583 - val_loss: 0.2822 - val_accuracy: 0.9147\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1069 - accuracy: 0.9629 - val_loss: 0.3106 - val_accuracy: 0.9013\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1152 - accuracy: 0.9589 - val_loss: 0.2955 - val_accuracy: 0.8876\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1166 - accuracy: 0.9563 - val_loss: 0.2950 - val_accuracy: 0.8884\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 0.9560 - val_loss: 0.2703 - val_accuracy: 0.9231\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1128 - accuracy: 0.9612 - val_loss: 0.3045 - val_accuracy: 0.9092\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1138 - accuracy: 0.9574 - val_loss: 0.2700 - val_accuracy: 0.9030\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1346 - accuracy: 0.9520 - val_loss: 0.2777 - val_accuracy: 0.9147\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1337 - accuracy: 0.9517 - val_loss: 0.2638 - val_accuracy: 0.9149\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1109 - accuracy: 0.9582 - val_loss: 0.2955 - val_accuracy: 0.9067\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9541 - val_loss: 0.3125 - val_accuracy: 0.8976\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1410 - accuracy: 0.9484 - val_loss: 0.3205 - val_accuracy: 0.8894\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1077 - accuracy: 0.9575 - val_loss: 0.2667 - val_accuracy: 0.9055\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1052 - accuracy: 0.9611 - val_loss: 0.3093 - val_accuracy: 0.9040\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9586 - val_loss: 0.2908 - val_accuracy: 0.9039\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9610 - val_loss: 0.2909 - val_accuracy: 0.9039\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9525 - val_loss: 0.3027 - val_accuracy: 0.8970\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1121 - accuracy: 0.9563 - val_loss: 0.2587 - val_accuracy: 0.9098\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9489 - val_loss: 0.2753 - val_accuracy: 0.9193\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1073 - accuracy: 0.9598 - val_loss: 0.2911 - val_accuracy: 0.9004\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1073 - accuracy: 0.9614 - val_loss: 0.3037 - val_accuracy: 0.9113\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1015 - accuracy: 0.9620 - val_loss: 0.3277 - val_accuracy: 0.8987\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1023 - accuracy: 0.9636 - val_loss: 0.3171 - val_accuracy: 0.8991\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.9583 - val_loss: 0.2369 - val_accuracy: 0.9146\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1456 - accuracy: 0.9424 - val_loss: 0.2821 - val_accuracy: 0.8985\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1136 - accuracy: 0.9564 - val_loss: 0.2487 - val_accuracy: 0.9121\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9523 - val_loss: 0.2981 - val_accuracy: 0.9048\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1129 - accuracy: 0.9585 - val_loss: 0.2897 - val_accuracy: 0.9068\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1136 - accuracy: 0.9577 - val_loss: 0.2668 - val_accuracy: 0.9275\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0991 - accuracy: 0.9612 - val_loss: 0.2565 - val_accuracy: 0.9238\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1190 - accuracy: 0.9563 - val_loss: 0.2729 - val_accuracy: 0.9070\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1282 - accuracy: 0.9572 - val_loss: 0.2698 - val_accuracy: 0.9094\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1068 - accuracy: 0.9613 - val_loss: 0.2513 - val_accuracy: 0.9156\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1116 - accuracy: 0.9598 - val_loss: 0.2795 - val_accuracy: 0.9100\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.2846 - val_accuracy: 0.9129\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1033 - accuracy: 0.9595 - val_loss: 0.3644 - val_accuracy: 0.9052\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 0.2846 - val_accuracy: 0.9080\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9640 - val_loss: 0.2972 - val_accuracy: 0.8984\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1125 - accuracy: 0.9603 - val_loss: 0.2689 - val_accuracy: 0.9104\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1045 - accuracy: 0.9608 - val_loss: 0.2644 - val_accuracy: 0.9071\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1078 - accuracy: 0.9584 - val_loss: 0.2943 - val_accuracy: 0.8945\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1167 - accuracy: 0.9581 - val_loss: 0.3355 - val_accuracy: 0.8967\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1014 - accuracy: 0.9592 - val_loss: 0.2950 - val_accuracy: 0.9076\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0985 - accuracy: 0.9629 - val_loss: 0.3083 - val_accuracy: 0.8993\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1241 - accuracy: 0.9525 - val_loss: 0.2868 - val_accuracy: 0.9097\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9666 - val_loss: 0.4111 - val_accuracy: 0.8817\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9584 - val_loss: 0.2637 - val_accuracy: 0.9299\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1012 - accuracy: 0.9629 - val_loss: 0.2864 - val_accuracy: 0.9180\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1033 - accuracy: 0.9621 - val_loss: 0.3059 - val_accuracy: 0.9124\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9626 - val_loss: 0.3533 - val_accuracy: 0.9042\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1060 - accuracy: 0.9602 - val_loss: 0.3122 - val_accuracy: 0.9009\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0985 - accuracy: 0.9640 - val_loss: 0.3502 - val_accuracy: 0.9015\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.3536 - val_accuracy: 0.8984\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1090 - accuracy: 0.9577 - val_loss: 0.3264 - val_accuracy: 0.9112\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0912 - accuracy: 0.9650 - val_loss: 0.3335 - val_accuracy: 0.8891\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1154 - accuracy: 0.9594 - val_loss: 0.2925 - val_accuracy: 0.9143\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 0.9606 - val_loss: 0.3514 - val_accuracy: 0.8945\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1117 - accuracy: 0.9573 - val_loss: 0.2780 - val_accuracy: 0.9156\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1033 - accuracy: 0.9642 - val_loss: 0.2806 - val_accuracy: 0.9193\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0921 - accuracy: 0.9660 - val_loss: 0.2840 - val_accuracy: 0.9031\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1073 - accuracy: 0.9585 - val_loss: 0.2718 - val_accuracy: 0.9126\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0955 - accuracy: 0.9673 - val_loss: 0.4776 - val_accuracy: 0.8641\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 0.9536 - val_loss: 0.3085 - val_accuracy: 0.8975\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1067 - accuracy: 0.9605 - val_loss: 0.2715 - val_accuracy: 0.9168\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1002 - accuracy: 0.9636 - val_loss: 0.3228 - val_accuracy: 0.8985\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0940 - accuracy: 0.9654 - val_loss: 0.3830 - val_accuracy: 0.9033\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0939 - accuracy: 0.9650 - val_loss: 0.2893 - val_accuracy: 0.9101\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9670 - val_loss: 0.3122 - val_accuracy: 0.9147\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0800 - accuracy: 0.9685 - val_loss: 0.3500 - val_accuracy: 0.8918\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0960 - accuracy: 0.9627 - val_loss: 0.3129 - val_accuracy: 0.9091\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0841 - accuracy: 0.9674 - val_loss: 0.3221 - val_accuracy: 0.9062\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1110 - accuracy: 0.9582 - val_loss: 0.3585 - val_accuracy: 0.8879\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1042 - accuracy: 0.9596 - val_loss: 0.2738 - val_accuracy: 0.9161\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0875 - accuracy: 0.9689 - val_loss: 0.2872 - val_accuracy: 0.9060\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.2606 - val_accuracy: 0.9207\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1017 - accuracy: 0.9635 - val_loss: 0.3159 - val_accuracy: 0.9034\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1097 - accuracy: 0.9591 - val_loss: 0.3869 - val_accuracy: 0.8942\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1103 - accuracy: 0.9578 - val_loss: 0.2318 - val_accuracy: 0.9216\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1159 - accuracy: 0.9552 - val_loss: 0.2799 - val_accuracy: 0.9208\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1032 - accuracy: 0.9599 - val_loss: 0.3144 - val_accuracy: 0.9150\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0947 - accuracy: 0.9649 - val_loss: 0.3520 - val_accuracy: 0.9051\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0976 - accuracy: 0.9639 - val_loss: 0.3812 - val_accuracy: 0.9070\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1019 - accuracy: 0.9627 - val_loss: 0.3347 - val_accuracy: 0.9134\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0998 - accuracy: 0.9648 - val_loss: 0.3079 - val_accuracy: 0.9092\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9685 - val_loss: 0.3322 - val_accuracy: 0.9016\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1064 - accuracy: 0.9592 - val_loss: 0.3270 - val_accuracy: 0.9143\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0914 - accuracy: 0.9665 - val_loss: 0.3195 - val_accuracy: 0.9015\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1031 - accuracy: 0.9632 - val_loss: 0.3097 - val_accuracy: 0.9115\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9625 - val_loss: 0.3583 - val_accuracy: 0.9174\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1172 - accuracy: 0.9591 - val_loss: 0.2956 - val_accuracy: 0.9121\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1108 - accuracy: 0.9556 - val_loss: 0.2847 - val_accuracy: 0.9179\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0882 - accuracy: 0.9662 - val_loss: 0.3140 - val_accuracy: 0.9101\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0797 - accuracy: 0.9712 - val_loss: 0.2875 - val_accuracy: 0.9183\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9660 - val_loss: 0.3412 - val_accuracy: 0.9097\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1095 - accuracy: 0.9585 - val_loss: 0.2760 - val_accuracy: 0.9174\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0911 - accuracy: 0.9635 - val_loss: 0.3400 - val_accuracy: 0.9004\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0917 - accuracy: 0.9654 - val_loss: 0.3879 - val_accuracy: 0.8961\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0917 - accuracy: 0.9650 - val_loss: 0.3007 - val_accuracy: 0.9198\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.3097 - val_accuracy: 0.9171\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1006 - accuracy: 0.9629 - val_loss: 0.3215 - val_accuracy: 0.9058\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0838 - accuracy: 0.9681 - val_loss: 0.3760 - val_accuracy: 0.8939\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1055 - accuracy: 0.9611 - val_loss: 0.3904 - val_accuracy: 0.8780\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0985 - accuracy: 0.9617 - val_loss: 0.3824 - val_accuracy: 0.9015\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0771 - accuracy: 0.9718 - val_loss: 0.3126 - val_accuracy: 0.9165\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0775 - accuracy: 0.9705 - val_loss: 0.3613 - val_accuracy: 0.9080\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0902 - accuracy: 0.9663 - val_loss: 0.3270 - val_accuracy: 0.9094\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0921 - accuracy: 0.9658 - val_loss: 0.3323 - val_accuracy: 0.9150\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0833 - accuracy: 0.9699 - val_loss: 0.3272 - val_accuracy: 0.9025\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9650 - val_loss: 0.3558 - val_accuracy: 0.8970\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0918 - accuracy: 0.9649 - val_loss: 0.3653 - val_accuracy: 0.8990\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0919 - accuracy: 0.9650 - val_loss: 0.3236 - val_accuracy: 0.9115\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0908 - accuracy: 0.9670 - val_loss: 0.3178 - val_accuracy: 0.9058\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1197 - accuracy: 0.9523 - val_loss: 0.3334 - val_accuracy: 0.8999\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1151 - accuracy: 0.9564 - val_loss: 0.3999 - val_accuracy: 0.8839\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1120 - accuracy: 0.9556 - val_loss: 0.2917 - val_accuracy: 0.9091\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1096 - accuracy: 0.9587 - val_loss: 0.3340 - val_accuracy: 0.9107\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1120 - accuracy: 0.9582 - val_loss: 0.3144 - val_accuracy: 0.9042\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1089 - accuracy: 0.9584 - val_loss: 0.3436 - val_accuracy: 0.8945\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0933 - accuracy: 0.9682 - val_loss: 0.4297 - val_accuracy: 0.8795\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.9671 - val_loss: 0.3703 - val_accuracy: 0.8990\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0810 - accuracy: 0.9719 - val_loss: 0.3844 - val_accuracy: 0.9049\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 0.9612 - val_loss: 0.4037 - val_accuracy: 0.8929\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1075 - accuracy: 0.9583 - val_loss: 0.3783 - val_accuracy: 0.8966\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1005 - accuracy: 0.9598 - val_loss: 0.3147 - val_accuracy: 0.9134\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 0.9630 - val_loss: 0.2935 - val_accuracy: 0.9082\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0955 - accuracy: 0.9627 - val_loss: 0.2974 - val_accuracy: 0.9068\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1025 - accuracy: 0.9609 - val_loss: 0.3081 - val_accuracy: 0.9070\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9680 - val_loss: 0.3162 - val_accuracy: 0.9129\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.9754 - val_loss: 0.3504 - val_accuracy: 0.9055\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0787 - accuracy: 0.9684 - val_loss: 0.3828 - val_accuracy: 0.9021\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0776 - accuracy: 0.9701 - val_loss: 0.3343 - val_accuracy: 0.9112\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0861 - accuracy: 0.9682 - val_loss: 0.3141 - val_accuracy: 0.9086\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0817 - accuracy: 0.9698 - val_loss: 0.3720 - val_accuracy: 0.8958\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9684 - val_loss: 0.2901 - val_accuracy: 0.9121\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0872 - accuracy: 0.9684 - val_loss: 0.3575 - val_accuracy: 0.9052\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0916 - accuracy: 0.9648 - val_loss: 0.3417 - val_accuracy: 0.8920\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1228 - accuracy: 0.9551 - val_loss: 0.2994 - val_accuracy: 0.9124\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.9653 - val_loss: 0.3173 - val_accuracy: 0.9138\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0872 - accuracy: 0.9666 - val_loss: 0.3041 - val_accuracy: 0.9132\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9672 - val_loss: 0.4045 - val_accuracy: 0.8838\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9617 - val_loss: 0.3364 - val_accuracy: 0.9098\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0929 - accuracy: 0.9643 - val_loss: 0.3223 - val_accuracy: 0.9004\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.2827 - val_accuracy: 0.9170\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0925 - accuracy: 0.9656 - val_loss: 0.3484 - val_accuracy: 0.9028\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0880 - accuracy: 0.9669 - val_loss: 0.3374 - val_accuracy: 0.9049\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9644 - val_loss: 0.2952 - val_accuracy: 0.9089\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9645 - val_loss: 0.3147 - val_accuracy: 0.9037\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.9715 - val_loss: 0.3253 - val_accuracy: 0.9080\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 0.9660 - val_loss: 0.3168 - val_accuracy: 0.8985\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1166 - accuracy: 0.9530 - val_loss: 0.2747 - val_accuracy: 0.9185\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9644 - val_loss: 0.3212 - val_accuracy: 0.8988\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0979 - accuracy: 0.9620 - val_loss: 0.3714 - val_accuracy: 0.8876\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.9647 - val_loss: 0.3023 - val_accuracy: 0.9065\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9574 - val_loss: 0.3111 - val_accuracy: 0.9045\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1242 - accuracy: 0.9556 - val_loss: 0.3169 - val_accuracy: 0.9076\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0975 - accuracy: 0.9654 - val_loss: 0.3290 - val_accuracy: 0.9104\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9599 - val_loss: 0.3274 - val_accuracy: 0.9076\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1008 - accuracy: 0.9610 - val_loss: 0.3858 - val_accuracy: 0.8903\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0917 - accuracy: 0.9669 - val_loss: 0.3814 - val_accuracy: 0.9021\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0707 - accuracy: 0.9747 - val_loss: 0.3638 - val_accuracy: 0.9077\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9752 - val_loss: 0.3740 - val_accuracy: 0.9046\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9702 - val_loss: 0.3524 - val_accuracy: 0.8984\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0885 - accuracy: 0.9693 - val_loss: 0.3495 - val_accuracy: 0.9065\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1029 - accuracy: 0.9647 - val_loss: 0.3788 - val_accuracy: 0.9051\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0788 - accuracy: 0.9707 - val_loss: 0.3969 - val_accuracy: 0.9009\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9685 - val_loss: 0.4069 - val_accuracy: 0.9058\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9722 - val_loss: 0.3670 - val_accuracy: 0.9028\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0873 - accuracy: 0.9662 - val_loss: 0.3531 - val_accuracy: 0.9018\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1008 - accuracy: 0.9573 - val_loss: 0.3767 - val_accuracy: 0.9007\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1162 - accuracy: 0.9575 - val_loss: 0.3385 - val_accuracy: 0.9031\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0968 - accuracy: 0.9626 - val_loss: 0.3732 - val_accuracy: 0.9082\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0765 - accuracy: 0.9720 - val_loss: 0.4493 - val_accuracy: 0.8874\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9643 - val_loss: 0.4516 - val_accuracy: 0.8862\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.3824 - val_accuracy: 0.9033\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9653 - val_loss: 0.3672 - val_accuracy: 0.9022\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9655 - val_loss: 0.3362 - val_accuracy: 0.9165\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0826 - accuracy: 0.9680 - val_loss: 0.3482 - val_accuracy: 0.9098\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9616 - val_loss: 0.3220 - val_accuracy: 0.9007\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9698 - val_loss: 0.3298 - val_accuracy: 0.9119\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0861 - accuracy: 0.9676 - val_loss: 0.3118 - val_accuracy: 0.9135\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0633 - accuracy: 0.9764 - val_loss: 0.3695 - val_accuracy: 0.9110\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0714 - accuracy: 0.9732 - val_loss: 0.3349 - val_accuracy: 0.9122\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0721 - accuracy: 0.9744 - val_loss: 0.3884 - val_accuracy: 0.8994\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0912 - accuracy: 0.9638 - val_loss: 0.3792 - val_accuracy: 0.8958\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0809 - accuracy: 0.9719 - val_loss: 0.3369 - val_accuracy: 0.9058\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0871 - accuracy: 0.9675 - val_loss: 0.3416 - val_accuracy: 0.9046\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1080 - accuracy: 0.9595 - val_loss: 0.3311 - val_accuracy: 0.9036\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0909 - accuracy: 0.9678 - val_loss: 0.3293 - val_accuracy: 0.9161\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.3203 - val_accuracy: 0.9039\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0892 - accuracy: 0.9645 - val_loss: 0.3213 - val_accuracy: 0.9112\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0960 - accuracy: 0.9651 - val_loss: 0.3317 - val_accuracy: 0.9112\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0865 - accuracy: 0.9662 - val_loss: 0.2968 - val_accuracy: 0.9140\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 0.3900 - val_accuracy: 0.9034\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.3523 - val_accuracy: 0.9124\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9686 - val_loss: 0.3200 - val_accuracy: 0.9074\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1065 - accuracy: 0.9596 - val_loss: 0.3458 - val_accuracy: 0.8951\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.9506 - val_loss: 0.3394 - val_accuracy: 0.9146\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1026 - accuracy: 0.9624 - val_loss: 0.3225 - val_accuracy: 0.9156\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1087 - accuracy: 0.9599 - val_loss: 0.3240 - val_accuracy: 0.8949\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1092 - accuracy: 0.9616 - val_loss: 0.3480 - val_accuracy: 0.9043\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0895 - accuracy: 0.9646 - val_loss: 0.3779 - val_accuracy: 0.8917\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1027 - accuracy: 0.9606 - val_loss: 0.3553 - val_accuracy: 0.9000\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0850 - accuracy: 0.9663 - val_loss: 0.3676 - val_accuracy: 0.8943\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1017 - accuracy: 0.9612 - val_loss: 0.3647 - val_accuracy: 0.8960\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0933 - accuracy: 0.9658 - val_loss: 0.3733 - val_accuracy: 0.8875\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9669 - val_loss: 0.3466 - val_accuracy: 0.9088\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0875 - accuracy: 0.9672 - val_loss: 0.3650 - val_accuracy: 0.8999\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0957 - accuracy: 0.9620 - val_loss: 0.3389 - val_accuracy: 0.8993\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0967 - accuracy: 0.9603 - val_loss: 0.3960 - val_accuracy: 0.8932\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0913 - accuracy: 0.9637 - val_loss: 0.3893 - val_accuracy: 0.8975\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 0.9586 - val_loss: 0.3159 - val_accuracy: 0.8948\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.9660 - val_loss: 0.3109 - val_accuracy: 0.9137\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.3659 - val_accuracy: 0.8987\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0862 - accuracy: 0.9666 - val_loss: 0.3567 - val_accuracy: 0.9000\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.3607 - val_accuracy: 0.8972\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0832 - accuracy: 0.9683 - val_loss: 0.3578 - val_accuracy: 0.9025\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0708 - accuracy: 0.9720 - val_loss: 0.3570 - val_accuracy: 0.9082\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0851 - accuracy: 0.9686 - val_loss: 0.3866 - val_accuracy: 0.9110\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0959 - accuracy: 0.9653 - val_loss: 0.3068 - val_accuracy: 0.9144\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 0.3666 - val_accuracy: 0.9143\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0831 - accuracy: 0.9704 - val_loss: 0.3783 - val_accuracy: 0.9037\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.3450 - val_accuracy: 0.9015\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0793 - accuracy: 0.9718 - val_loss: 0.3575 - val_accuracy: 0.9082\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0745 - accuracy: 0.9747 - val_loss: 0.3790 - val_accuracy: 0.8935\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0824 - accuracy: 0.9669 - val_loss: 0.4400 - val_accuracy: 0.8914\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0899 - accuracy: 0.9676 - val_loss: 0.3732 - val_accuracy: 0.9019\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0795 - accuracy: 0.9712 - val_loss: 0.3729 - val_accuracy: 0.9060\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 0.9688 - val_loss: 0.3225 - val_accuracy: 0.9146\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0694 - accuracy: 0.9759 - val_loss: 0.3447 - val_accuracy: 0.9107\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 0.9775 - val_loss: 0.3561 - val_accuracy: 0.9067\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0750 - accuracy: 0.9732 - val_loss: 0.3272 - val_accuracy: 0.9077\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9741 - val_loss: 0.3477 - val_accuracy: 0.9179\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9768 - val_loss: 0.4000 - val_accuracy: 0.9021\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0699 - accuracy: 0.9760 - val_loss: 0.4275 - val_accuracy: 0.8842\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0806 - accuracy: 0.9691 - val_loss: 0.3899 - val_accuracy: 0.9086\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.4103 - val_accuracy: 0.9012\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9711 - val_loss: 0.3636 - val_accuracy: 0.9174\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0600 - accuracy: 0.9765 - val_loss: 0.3747 - val_accuracy: 0.9088\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.3563 - val_accuracy: 0.9113\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0823 - accuracy: 0.9702 - val_loss: 0.3674 - val_accuracy: 0.9046\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9650 - val_loss: 0.3727 - val_accuracy: 0.8939\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0793 - accuracy: 0.9687 - val_loss: 0.4102 - val_accuracy: 0.8882\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0785 - accuracy: 0.9692 - val_loss: 0.3691 - val_accuracy: 0.9061\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9670 - val_loss: 0.4167 - val_accuracy: 0.8930\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1080 - accuracy: 0.9567 - val_loss: 0.3503 - val_accuracy: 0.9003\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9565 - val_loss: 0.3542 - val_accuracy: 0.8972\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1045 - accuracy: 0.9603 - val_loss: 0.3251 - val_accuracy: 0.9115\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0809 - accuracy: 0.9689 - val_loss: 0.4030 - val_accuracy: 0.8942\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0868 - accuracy: 0.9674 - val_loss: 0.3342 - val_accuracy: 0.8997\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0862 - accuracy: 0.9680 - val_loss: 0.4171 - val_accuracy: 0.8824\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9638 - val_loss: 0.3322 - val_accuracy: 0.9085\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1012 - accuracy: 0.9593 - val_loss: 0.3460 - val_accuracy: 0.8955\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0919 - accuracy: 0.9643 - val_loss: 0.3214 - val_accuracy: 0.9112\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0905 - accuracy: 0.9674 - val_loss: 0.3984 - val_accuracy: 0.8964\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.9642 - val_loss: 0.3232 - val_accuracy: 0.9077\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0972 - accuracy: 0.9631 - val_loss: 0.3233 - val_accuracy: 0.9061\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0804 - accuracy: 0.9711 - val_loss: 0.3690 - val_accuracy: 0.8932\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9698 - val_loss: 0.3935 - val_accuracy: 0.8935\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0735 - accuracy: 0.9719 - val_loss: 0.3770 - val_accuracy: 0.8978\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0841 - accuracy: 0.9647 - val_loss: 0.3764 - val_accuracy: 0.9033\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0724 - accuracy: 0.9726 - val_loss: 0.4105 - val_accuracy: 0.8924\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0851 - accuracy: 0.9705 - val_loss: 0.4065 - val_accuracy: 0.8936\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1111 - accuracy: 0.9568 - val_loss: 0.3471 - val_accuracy: 0.9042\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0988 - accuracy: 0.9627 - val_loss: 0.3769 - val_accuracy: 0.9000\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0759 - accuracy: 0.9719 - val_loss: 0.3293 - val_accuracy: 0.9119\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0906 - accuracy: 0.9682 - val_loss: 0.3307 - val_accuracy: 0.9015\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0841 - accuracy: 0.9689 - val_loss: 0.3461 - val_accuracy: 0.9147\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0762 - accuracy: 0.9722 - val_loss: 0.3589 - val_accuracy: 0.9054\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0801 - accuracy: 0.9699 - val_loss: 0.3565 - val_accuracy: 0.8997\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0967 - accuracy: 0.9642 - val_loss: 0.2753 - val_accuracy: 0.9132\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0741 - accuracy: 0.9713 - val_loss: 0.3179 - val_accuracy: 0.9207\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1047 - accuracy: 0.9617 - val_loss: 0.3220 - val_accuracy: 0.9153\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9686 - val_loss: 0.3357 - val_accuracy: 0.9205\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0819 - accuracy: 0.9682 - val_loss: 0.3267 - val_accuracy: 0.9198\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 0.9625 - val_loss: 0.2987 - val_accuracy: 0.9201\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0812 - accuracy: 0.9693 - val_loss: 0.3012 - val_accuracy: 0.9149\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0944 - accuracy: 0.9638 - val_loss: 0.2940 - val_accuracy: 0.9201\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0825 - accuracy: 0.9666 - val_loss: 0.3289 - val_accuracy: 0.9037\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.9614 - val_loss: 0.3855 - val_accuracy: 0.9015\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0860 - accuracy: 0.9655 - val_loss: 0.2968 - val_accuracy: 0.9173\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0721 - accuracy: 0.9712 - val_loss: 0.3420 - val_accuracy: 0.9112\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0782 - accuracy: 0.9691 - val_loss: 0.3513 - val_accuracy: 0.9091\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0916 - accuracy: 0.9638 - val_loss: 0.3117 - val_accuracy: 0.9141\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1081 - accuracy: 0.9639 - val_loss: 0.2780 - val_accuracy: 0.9074\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0961 - accuracy: 0.9635 - val_loss: 0.3616 - val_accuracy: 0.9079\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0827 - accuracy: 0.9693 - val_loss: 0.3251 - val_accuracy: 0.9109\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.9626 - val_loss: 0.3276 - val_accuracy: 0.9095\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0780 - accuracy: 0.9703 - val_loss: 0.3705 - val_accuracy: 0.9003\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0933 - accuracy: 0.9637 - val_loss: 0.3208 - val_accuracy: 0.9094\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0664 - accuracy: 0.9748 - val_loss: 0.3277 - val_accuracy: 0.9152\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0649 - accuracy: 0.9742 - val_loss: 0.4071 - val_accuracy: 0.9012\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0713 - accuracy: 0.9740 - val_loss: 0.3396 - val_accuracy: 0.9109\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 0.3191 - val_accuracy: 0.9098\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0827 - accuracy: 0.9682 - val_loss: 0.2922 - val_accuracy: 0.9183\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9714 - val_loss: 0.3758 - val_accuracy: 0.8966\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 0.3945 - val_accuracy: 0.8918\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0789 - accuracy: 0.9692 - val_loss: 0.3481 - val_accuracy: 0.9095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxrLHhr5iTkP",
        "outputId": "fc318b4d-9740-4f14-ebff-96723edddf66"
      },
      "source": [
        "history2 = model2.fit(Xtrain, Ytrain, batch_size =100, epochs = 500, verbose = 1, validation_data=(Xval, Yval),callbacks=checkpoint2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 12s 96ms/step - loss: 1.2028 - accuracy: 0.6634 - val_loss: 1.0146 - val_accuracy: 0.8006\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.9404 - accuracy: 0.8451 - val_loss: 0.9030 - val_accuracy: 0.8393\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.8239 - accuracy: 0.8780 - val_loss: 0.7860 - val_accuracy: 0.8780\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.7399 - accuracy: 0.8925 - val_loss: 0.7217 - val_accuracy: 0.8876\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6945 - accuracy: 0.8954 - val_loss: 0.7521 - val_accuracy: 0.8562\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6285 - accuracy: 0.9098 - val_loss: 0.6713 - val_accuracy: 0.8689\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.5967 - accuracy: 0.9127 - val_loss: 0.6427 - val_accuracy: 0.8682\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.5366 - accuracy: 0.9192 - val_loss: 0.5868 - val_accuracy: 0.9007\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.5063 - accuracy: 0.9329 - val_loss: 0.6016 - val_accuracy: 0.8591\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.4923 - accuracy: 0.9168 - val_loss: 0.6318 - val_accuracy: 0.8382\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.4600 - accuracy: 0.9238 - val_loss: 0.7375 - val_accuracy: 0.8109\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.4575 - accuracy: 0.9124 - val_loss: 0.5557 - val_accuracy: 0.8659\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.4200 - accuracy: 0.9199 - val_loss: 0.5661 - val_accuracy: 0.8573\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3958 - accuracy: 0.9258 - val_loss: 0.6689 - val_accuracy: 0.8350\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4323 - accuracy: 0.9072 - val_loss: 0.4719 - val_accuracy: 0.8802\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3364 - accuracy: 0.9273 - val_loss: 0.5032 - val_accuracy: 0.8632\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3574 - accuracy: 0.9206 - val_loss: 0.4174 - val_accuracy: 0.8725\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3318 - accuracy: 0.9221 - val_loss: 0.4195 - val_accuracy: 0.8866\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.3094 - accuracy: 0.9265 - val_loss: 0.3726 - val_accuracy: 0.9027\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2843 - accuracy: 0.9416 - val_loss: 0.4630 - val_accuracy: 0.8501\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.2835 - accuracy: 0.9315 - val_loss: 0.4455 - val_accuracy: 0.8744\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3014 - accuracy: 0.9174 - val_loss: 0.4026 - val_accuracy: 0.8731\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2571 - accuracy: 0.9370 - val_loss: 0.4696 - val_accuracy: 0.8653\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2576 - accuracy: 0.9285 - val_loss: 0.3763 - val_accuracy: 0.8888\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2449 - accuracy: 0.9363 - val_loss: 0.4536 - val_accuracy: 0.8661\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.2354 - accuracy: 0.9398 - val_loss: 0.3658 - val_accuracy: 0.8729\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2436 - accuracy: 0.9284 - val_loss: 0.4193 - val_accuracy: 0.8844\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2294 - accuracy: 0.9316 - val_loss: 0.3567 - val_accuracy: 0.8911\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2018 - accuracy: 0.9355 - val_loss: 0.3573 - val_accuracy: 0.8775\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1781 - accuracy: 0.9558 - val_loss: 0.4539 - val_accuracy: 0.8528\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.2030 - accuracy: 0.9395 - val_loss: 0.2806 - val_accuracy: 0.9170\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1868 - accuracy: 0.9393 - val_loss: 0.2838 - val_accuracy: 0.9052\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1767 - accuracy: 0.9485 - val_loss: 0.3113 - val_accuracy: 0.9077\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1698 - accuracy: 0.9452 - val_loss: 0.2840 - val_accuracy: 0.9116\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1669 - accuracy: 0.9456 - val_loss: 0.3064 - val_accuracy: 0.9073\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1691 - accuracy: 0.9478 - val_loss: 0.2695 - val_accuracy: 0.9177\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1728 - accuracy: 0.9465 - val_loss: 0.4204 - val_accuracy: 0.8624\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1984 - accuracy: 0.9315 - val_loss: 0.3219 - val_accuracy: 0.9064\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1614 - accuracy: 0.9417 - val_loss: 0.3681 - val_accuracy: 0.8939\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1568 - accuracy: 0.9483 - val_loss: 0.2589 - val_accuracy: 0.9143\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1457 - accuracy: 0.9492 - val_loss: 0.2616 - val_accuracy: 0.9094\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1257 - accuracy: 0.9680 - val_loss: 0.2832 - val_accuracy: 0.9125\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1411 - accuracy: 0.9490 - val_loss: 0.3131 - val_accuracy: 0.8893\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1551 - accuracy: 0.9488 - val_loss: 0.2393 - val_accuracy: 0.9193\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1369 - accuracy: 0.9513 - val_loss: 0.3542 - val_accuracy: 0.8915\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1657 - accuracy: 0.9417 - val_loss: 0.2948 - val_accuracy: 0.8982\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1405 - accuracy: 0.9511 - val_loss: 0.2754 - val_accuracy: 0.9062\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1505 - accuracy: 0.9433 - val_loss: 0.2799 - val_accuracy: 0.9060\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1348 - accuracy: 0.9559 - val_loss: 0.3212 - val_accuracy: 0.8841\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1202 - accuracy: 0.9569 - val_loss: 0.3564 - val_accuracy: 0.8774\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1272 - accuracy: 0.9529 - val_loss: 0.3245 - val_accuracy: 0.9159\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1332 - accuracy: 0.9509 - val_loss: 0.3019 - val_accuracy: 0.8966\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1471 - accuracy: 0.9472 - val_loss: 0.2448 - val_accuracy: 0.9146\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1275 - accuracy: 0.9548 - val_loss: 0.2646 - val_accuracy: 0.8988\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1183 - accuracy: 0.9614 - val_loss: 0.2863 - val_accuracy: 0.8943\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1484 - accuracy: 0.9453 - val_loss: 0.3008 - val_accuracy: 0.8772\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1302 - accuracy: 0.9536 - val_loss: 0.2512 - val_accuracy: 0.9083\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1310 - accuracy: 0.9549 - val_loss: 0.3374 - val_accuracy: 0.8808\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1586 - accuracy: 0.9396 - val_loss: 0.2795 - val_accuracy: 0.8915\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1192 - accuracy: 0.9570 - val_loss: 0.4741 - val_accuracy: 0.8403\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1632 - accuracy: 0.9328 - val_loss: 0.3301 - val_accuracy: 0.8796\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1366 - accuracy: 0.9501 - val_loss: 0.3863 - val_accuracy: 0.9004\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1244 - accuracy: 0.9574 - val_loss: 0.3222 - val_accuracy: 0.8875\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1325 - accuracy: 0.9456 - val_loss: 0.3840 - val_accuracy: 0.8762\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1009 - accuracy: 0.9617 - val_loss: 0.3558 - val_accuracy: 0.8863\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1627 - accuracy: 0.9380 - val_loss: 0.3214 - val_accuracy: 0.8954\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.2357 - val_accuracy: 0.9110\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1151 - accuracy: 0.9641 - val_loss: 0.2945 - val_accuracy: 0.8943\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1215 - accuracy: 0.9531 - val_loss: 0.3250 - val_accuracy: 0.8946\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1176 - accuracy: 0.9521 - val_loss: 0.3624 - val_accuracy: 0.8841\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1353 - accuracy: 0.9493 - val_loss: 0.2971 - val_accuracy: 0.8973\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1199 - accuracy: 0.9566 - val_loss: 0.3473 - val_accuracy: 0.9022\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1159 - accuracy: 0.9503 - val_loss: 0.2735 - val_accuracy: 0.8939\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1128 - accuracy: 0.9601 - val_loss: 0.3455 - val_accuracy: 0.8955\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1127 - accuracy: 0.9593 - val_loss: 0.3131 - val_accuracy: 0.9034\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1179 - accuracy: 0.9568 - val_loss: 0.3339 - val_accuracy: 0.9058\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0808 - accuracy: 0.9674 - val_loss: 0.4376 - val_accuracy: 0.8699\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 0.3367 - val_accuracy: 0.8902\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1186 - accuracy: 0.9555 - val_loss: 0.2792 - val_accuracy: 0.8984\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1126 - accuracy: 0.9566 - val_loss: 0.3592 - val_accuracy: 0.8801\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1155 - accuracy: 0.9538 - val_loss: 0.3426 - val_accuracy: 0.8887\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1114 - accuracy: 0.9536 - val_loss: 0.3545 - val_accuracy: 0.8775\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1096 - accuracy: 0.9593 - val_loss: 0.4366 - val_accuracy: 0.8802\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1620 - accuracy: 0.9393 - val_loss: 0.3352 - val_accuracy: 0.8885\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1162 - accuracy: 0.9518 - val_loss: 0.4077 - val_accuracy: 0.8737\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1225 - accuracy: 0.9500 - val_loss: 0.3259 - val_accuracy: 0.8909\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1591 - accuracy: 0.9337 - val_loss: 0.3152 - val_accuracy: 0.8958\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9490 - val_loss: 0.3349 - val_accuracy: 0.8893\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1170 - accuracy: 0.9540 - val_loss: 0.3373 - val_accuracy: 0.8961\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1207 - accuracy: 0.9554 - val_loss: 0.2852 - val_accuracy: 0.9085\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1186 - accuracy: 0.9518 - val_loss: 0.2706 - val_accuracy: 0.9147\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1168 - accuracy: 0.9560 - val_loss: 0.2177 - val_accuracy: 0.9152\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1284 - accuracy: 0.9488 - val_loss: 0.3344 - val_accuracy: 0.8530\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1453 - accuracy: 0.9348 - val_loss: 0.3015 - val_accuracy: 0.9042\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1258 - accuracy: 0.9525 - val_loss: 0.2499 - val_accuracy: 0.8985\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1255 - accuracy: 0.9543 - val_loss: 0.3053 - val_accuracy: 0.9031\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1052 - accuracy: 0.9620 - val_loss: 0.3584 - val_accuracy: 0.9033\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1013 - accuracy: 0.9636 - val_loss: 0.3275 - val_accuracy: 0.8875\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1450 - accuracy: 0.9512 - val_loss: 0.3397 - val_accuracy: 0.9103\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1112 - accuracy: 0.9566 - val_loss: 0.3351 - val_accuracy: 0.8933\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1183 - accuracy: 0.9552 - val_loss: 0.3688 - val_accuracy: 0.9015\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1022 - accuracy: 0.9604 - val_loss: 0.3828 - val_accuracy: 0.8835\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1258 - accuracy: 0.9451 - val_loss: 0.3094 - val_accuracy: 0.9089\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.3320 - val_accuracy: 0.9089\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0986 - accuracy: 0.9665 - val_loss: 0.3603 - val_accuracy: 0.8879\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1181 - accuracy: 0.9532 - val_loss: 0.2661 - val_accuracy: 0.9037\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0918 - accuracy: 0.9610 - val_loss: 0.3763 - val_accuracy: 0.8890\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1109 - accuracy: 0.9603 - val_loss: 0.3376 - val_accuracy: 0.8842\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1021 - accuracy: 0.9591 - val_loss: 0.2791 - val_accuracy: 0.9065\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1118 - accuracy: 0.9607 - val_loss: 0.2933 - val_accuracy: 0.8961\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1236 - accuracy: 0.9506 - val_loss: 0.3770 - val_accuracy: 0.8900\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1298 - accuracy: 0.9489 - val_loss: 0.2766 - val_accuracy: 0.9080\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1057 - accuracy: 0.9617 - val_loss: 0.3229 - val_accuracy: 0.8841\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1083 - accuracy: 0.9577 - val_loss: 0.3589 - val_accuracy: 0.8984\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1191 - accuracy: 0.9558 - val_loss: 0.3531 - val_accuracy: 0.8905\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0887 - accuracy: 0.9685 - val_loss: 0.3409 - val_accuracy: 0.8975\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0936 - accuracy: 0.9640 - val_loss: 0.2938 - val_accuracy: 0.8955\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0954 - accuracy: 0.9653 - val_loss: 0.4106 - val_accuracy: 0.8576\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1313 - accuracy: 0.9454 - val_loss: 0.2919 - val_accuracy: 0.9076\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1254 - accuracy: 0.9537 - val_loss: 0.2895 - val_accuracy: 0.9254\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1213 - accuracy: 0.9590 - val_loss: 0.2869 - val_accuracy: 0.8997\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1040 - accuracy: 0.9618 - val_loss: 0.3007 - val_accuracy: 0.9018\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0933 - accuracy: 0.9677 - val_loss: 0.3096 - val_accuracy: 0.9022\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0760 - accuracy: 0.9750 - val_loss: 0.3588 - val_accuracy: 0.8993\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1248 - accuracy: 0.9529 - val_loss: 0.3056 - val_accuracy: 0.8979\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1249 - accuracy: 0.9500 - val_loss: 0.2758 - val_accuracy: 0.9241\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1307 - accuracy: 0.9488 - val_loss: 0.3471 - val_accuracy: 0.9012\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1118 - accuracy: 0.9549 - val_loss: 0.3238 - val_accuracy: 0.8830\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1204 - accuracy: 0.9496 - val_loss: 0.3350 - val_accuracy: 0.9019\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0989 - accuracy: 0.9632 - val_loss: 0.3740 - val_accuracy: 0.8970\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1216 - accuracy: 0.9490 - val_loss: 0.3779 - val_accuracy: 0.9010\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1393 - accuracy: 0.9409 - val_loss: 0.3722 - val_accuracy: 0.8771\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1183 - accuracy: 0.9507 - val_loss: 0.3288 - val_accuracy: 0.8938\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0949 - accuracy: 0.9597 - val_loss: 0.3515 - val_accuracy: 0.8802\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0953 - accuracy: 0.9659 - val_loss: 0.3042 - val_accuracy: 0.8973\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 0.3333 - val_accuracy: 0.8878\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0886 - accuracy: 0.9646 - val_loss: 0.3368 - val_accuracy: 0.8905\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0942 - accuracy: 0.9665 - val_loss: 0.4108 - val_accuracy: 0.8744\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1159 - accuracy: 0.9617 - val_loss: 0.4383 - val_accuracy: 0.8521\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0945 - accuracy: 0.9653 - val_loss: 0.3958 - val_accuracy: 0.8670\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1145 - accuracy: 0.9605 - val_loss: 0.3447 - val_accuracy: 0.8784\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0836 - accuracy: 0.9696 - val_loss: 0.3809 - val_accuracy: 0.8747\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1040 - accuracy: 0.9565 - val_loss: 0.3404 - val_accuracy: 0.8951\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1112 - accuracy: 0.9578 - val_loss: 0.3828 - val_accuracy: 0.8960\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0774 - accuracy: 0.9736 - val_loss: 0.4370 - val_accuracy: 0.8832\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1103 - accuracy: 0.9556 - val_loss: 0.3714 - val_accuracy: 0.8885\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1040 - accuracy: 0.9644 - val_loss: 0.4245 - val_accuracy: 0.8969\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.2991 - val_accuracy: 0.9033\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1029 - accuracy: 0.9587 - val_loss: 0.3391 - val_accuracy: 0.9125\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0848 - accuracy: 0.9609 - val_loss: 0.2997 - val_accuracy: 0.9146\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0751 - accuracy: 0.9756 - val_loss: 0.3885 - val_accuracy: 0.9082\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1157 - accuracy: 0.9599 - val_loss: 0.3200 - val_accuracy: 0.8972\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0876 - accuracy: 0.9664 - val_loss: 0.4077 - val_accuracy: 0.9104\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0895 - accuracy: 0.9659 - val_loss: 0.3249 - val_accuracy: 0.9019\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0909 - accuracy: 0.9674 - val_loss: 0.2734 - val_accuracy: 0.9153\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0753 - accuracy: 0.9725 - val_loss: 0.3372 - val_accuracy: 0.9091\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0981 - accuracy: 0.9646 - val_loss: 0.3985 - val_accuracy: 0.9010\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1015 - accuracy: 0.9650 - val_loss: 0.2657 - val_accuracy: 0.9146\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1071 - accuracy: 0.9592 - val_loss: 0.2340 - val_accuracy: 0.9094\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1147 - accuracy: 0.9615 - val_loss: 0.3696 - val_accuracy: 0.8996\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1076 - accuracy: 0.9583 - val_loss: 0.3300 - val_accuracy: 0.8969\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0816 - accuracy: 0.9720 - val_loss: 0.3035 - val_accuracy: 0.9107\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.3308 - val_accuracy: 0.8994\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0760 - accuracy: 0.9737 - val_loss: 0.3025 - val_accuracy: 0.9103\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0960 - accuracy: 0.9675 - val_loss: 0.3546 - val_accuracy: 0.8996\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0884 - accuracy: 0.9684 - val_loss: 0.3610 - val_accuracy: 0.8981\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0715 - accuracy: 0.9743 - val_loss: 0.3255 - val_accuracy: 0.9049\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.3575 - val_accuracy: 0.9051\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0679 - accuracy: 0.9745 - val_loss: 0.3160 - val_accuracy: 0.8871\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0810 - accuracy: 0.9674 - val_loss: 0.3818 - val_accuracy: 0.8778\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0910 - accuracy: 0.9649 - val_loss: 0.3619 - val_accuracy: 0.8762\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0890 - accuracy: 0.9661 - val_loss: 0.3104 - val_accuracy: 0.8929\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0858 - accuracy: 0.9700 - val_loss: 0.3581 - val_accuracy: 0.8856\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 0.3641 - val_accuracy: 0.9025\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0790 - accuracy: 0.9699 - val_loss: 0.3659 - val_accuracy: 0.8911\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0859 - accuracy: 0.9630 - val_loss: 0.3580 - val_accuracy: 0.8917\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0659 - accuracy: 0.9747 - val_loss: 0.3707 - val_accuracy: 0.8952\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.3262 - val_accuracy: 0.9155\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 0.3593 - val_accuracy: 0.8820\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0935 - accuracy: 0.9661 - val_loss: 0.3664 - val_accuracy: 0.9031\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0785 - accuracy: 0.9693 - val_loss: 0.3903 - val_accuracy: 0.8902\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1108 - accuracy: 0.9561 - val_loss: 0.3177 - val_accuracy: 0.8970\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0966 - accuracy: 0.9624 - val_loss: 0.3786 - val_accuracy: 0.9027\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0659 - accuracy: 0.9743 - val_loss: 0.3466 - val_accuracy: 0.8857\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1103 - accuracy: 0.9588 - val_loss: 0.2814 - val_accuracy: 0.9067\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0940 - accuracy: 0.9644 - val_loss: 0.3285 - val_accuracy: 0.8847\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1016 - accuracy: 0.9588 - val_loss: 0.4088 - val_accuracy: 0.8838\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1081 - accuracy: 0.9630 - val_loss: 0.3841 - val_accuracy: 0.9074\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0800 - accuracy: 0.9731 - val_loss: 0.4237 - val_accuracy: 0.8699\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0987 - accuracy: 0.9667 - val_loss: 0.3712 - val_accuracy: 0.9126\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0946 - accuracy: 0.9634 - val_loss: 0.2794 - val_accuracy: 0.9019\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 0.3605 - val_accuracy: 0.9080\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0820 - accuracy: 0.9690 - val_loss: 0.3208 - val_accuracy: 0.9140\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0841 - accuracy: 0.9670 - val_loss: 0.3479 - val_accuracy: 0.9027\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0859 - accuracy: 0.9686 - val_loss: 0.4315 - val_accuracy: 0.8997\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0639 - accuracy: 0.9773 - val_loss: 0.4400 - val_accuracy: 0.9033\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0817 - accuracy: 0.9702 - val_loss: 0.3626 - val_accuracy: 0.9003\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0772 - accuracy: 0.9735 - val_loss: 0.3418 - val_accuracy: 0.8930\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0695 - accuracy: 0.9765 - val_loss: 0.2995 - val_accuracy: 0.9048\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0901 - accuracy: 0.9635 - val_loss: 0.2843 - val_accuracy: 0.9004\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0773 - accuracy: 0.9751 - val_loss: 0.3435 - val_accuracy: 0.8942\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0805 - accuracy: 0.9700 - val_loss: 0.2829 - val_accuracy: 0.9158\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0800 - accuracy: 0.9683 - val_loss: 0.3311 - val_accuracy: 0.9043\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0789 - accuracy: 0.9744 - val_loss: 0.3468 - val_accuracy: 0.9131\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0554 - accuracy: 0.9785 - val_loss: 0.3750 - val_accuracy: 0.8881\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0747 - accuracy: 0.9733 - val_loss: 0.3540 - val_accuracy: 0.9042\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0689 - accuracy: 0.9724 - val_loss: 0.3105 - val_accuracy: 0.9246\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0533 - accuracy: 0.9814 - val_loss: 0.3560 - val_accuracy: 0.8999\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0643 - accuracy: 0.9748 - val_loss: 0.3929 - val_accuracy: 0.9065\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.3346 - val_accuracy: 0.9015\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0730 - accuracy: 0.9724 - val_loss: 0.4120 - val_accuracy: 0.9030\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0858 - accuracy: 0.9666 - val_loss: 0.3937 - val_accuracy: 0.8906\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0660 - accuracy: 0.9722 - val_loss: 0.4167 - val_accuracy: 0.9018\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0933 - accuracy: 0.9646 - val_loss: 0.3839 - val_accuracy: 0.8984\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0780 - accuracy: 0.9707 - val_loss: 0.3973 - val_accuracy: 0.8927\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.4131 - val_accuracy: 0.8936\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0639 - accuracy: 0.9751 - val_loss: 0.4078 - val_accuracy: 0.8924\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0654 - accuracy: 0.9752 - val_loss: 0.3592 - val_accuracy: 0.9042\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0713 - accuracy: 0.9747 - val_loss: 0.4587 - val_accuracy: 0.9030\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0707 - accuracy: 0.9688 - val_loss: 0.3673 - val_accuracy: 0.9226\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.3615 - val_accuracy: 0.8933\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.4122 - val_accuracy: 0.9060\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1036 - accuracy: 0.9598 - val_loss: 0.3402 - val_accuracy: 0.9115\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0842 - accuracy: 0.9712 - val_loss: 0.4444 - val_accuracy: 0.8920\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0885 - accuracy: 0.9664 - val_loss: 0.3663 - val_accuracy: 0.9052\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0700 - accuracy: 0.9754 - val_loss: 0.4200 - val_accuracy: 0.8811\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.3551 - val_accuracy: 0.9058\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0705 - accuracy: 0.9726 - val_loss: 0.4032 - val_accuracy: 0.8804\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0798 - accuracy: 0.9698 - val_loss: 0.3855 - val_accuracy: 0.8693\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 0.3679 - val_accuracy: 0.8954\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0658 - accuracy: 0.9727 - val_loss: 0.3719 - val_accuracy: 0.9016\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0811 - accuracy: 0.9714 - val_loss: 0.3900 - val_accuracy: 0.8946\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0715 - accuracy: 0.9697 - val_loss: 0.4615 - val_accuracy: 0.8884\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0881 - accuracy: 0.9695 - val_loss: 0.3339 - val_accuracy: 0.8923\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0694 - accuracy: 0.9792 - val_loss: 0.3243 - val_accuracy: 0.9135\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0795 - accuracy: 0.9702 - val_loss: 0.3526 - val_accuracy: 0.8863\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0661 - accuracy: 0.9755 - val_loss: 0.3280 - val_accuracy: 0.8960\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.3453 - val_accuracy: 0.9006\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0697 - accuracy: 0.9747 - val_loss: 0.3099 - val_accuracy: 0.8973\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0649 - accuracy: 0.9797 - val_loss: 0.2608 - val_accuracy: 0.9232\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0686 - accuracy: 0.9761 - val_loss: 0.3794 - val_accuracy: 0.9027\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0602 - accuracy: 0.9828 - val_loss: 0.3197 - val_accuracy: 0.9226\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.3996 - val_accuracy: 0.8994\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0742 - accuracy: 0.9729 - val_loss: 0.2907 - val_accuracy: 0.9162\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 0.3780 - val_accuracy: 0.9106\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.3500 - val_accuracy: 0.9115\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0672 - accuracy: 0.9737 - val_loss: 0.3931 - val_accuracy: 0.9073\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0632 - accuracy: 0.9745 - val_loss: 0.3498 - val_accuracy: 0.9144\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 0.3299 - val_accuracy: 0.9132\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0745 - accuracy: 0.9732 - val_loss: 0.3089 - val_accuracy: 0.9119\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0485 - accuracy: 0.9826 - val_loss: 0.3833 - val_accuracy: 0.9071\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0709 - accuracy: 0.9792 - val_loss: 0.3212 - val_accuracy: 0.8927\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0632 - accuracy: 0.9777 - val_loss: 0.4439 - val_accuracy: 0.8966\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.4912 - val_accuracy: 0.9019\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0598 - accuracy: 0.9789 - val_loss: 0.3967 - val_accuracy: 0.8830\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.2923 - val_accuracy: 0.9003\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0666 - accuracy: 0.9808 - val_loss: 0.3372 - val_accuracy: 0.9004\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0531 - accuracy: 0.9785 - val_loss: 0.4466 - val_accuracy: 0.8926\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.3612 - val_accuracy: 0.9122\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0458 - accuracy: 0.9826 - val_loss: 0.3433 - val_accuracy: 0.9079\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 0.3921 - val_accuracy: 0.8933\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0709 - accuracy: 0.9743 - val_loss: 0.4035 - val_accuracy: 0.9027\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0745 - accuracy: 0.9708 - val_loss: 0.2750 - val_accuracy: 0.9031\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0668 - accuracy: 0.9746 - val_loss: 0.3895 - val_accuracy: 0.8952\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0424 - accuracy: 0.9827 - val_loss: 0.4509 - val_accuracy: 0.8972\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.3640 - val_accuracy: 0.9067\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1026 - accuracy: 0.9661 - val_loss: 0.3355 - val_accuracy: 0.8835\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0838 - accuracy: 0.9697 - val_loss: 0.3422 - val_accuracy: 0.9034\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.3691 - val_accuracy: 0.9135\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.4008 - val_accuracy: 0.9137\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0461 - accuracy: 0.9834 - val_loss: 0.2789 - val_accuracy: 0.9216\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.4037 - val_accuracy: 0.9071\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0569 - accuracy: 0.9768 - val_loss: 0.3612 - val_accuracy: 0.9034\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.3761 - val_accuracy: 0.9129\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.3936 - val_accuracy: 0.9138\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 0.3828 - val_accuracy: 0.9137\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0664 - accuracy: 0.9749 - val_loss: 0.3981 - val_accuracy: 0.8940\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0625 - accuracy: 0.9769 - val_loss: 0.2925 - val_accuracy: 0.9079\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0928 - accuracy: 0.9672 - val_loss: 0.2887 - val_accuracy: 0.9060\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0533 - accuracy: 0.9790 - val_loss: 0.3386 - val_accuracy: 0.9140\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.4360 - val_accuracy: 0.9004\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0574 - accuracy: 0.9757 - val_loss: 0.3396 - val_accuracy: 0.8936\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.3167 - val_accuracy: 0.9164\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.2845 - val_accuracy: 0.9143\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0443 - accuracy: 0.9827 - val_loss: 0.4249 - val_accuracy: 0.8954\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0611 - accuracy: 0.9759 - val_loss: 0.3562 - val_accuracy: 0.8955\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0618 - accuracy: 0.9769 - val_loss: 0.3440 - val_accuracy: 0.9100\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0523 - accuracy: 0.9828 - val_loss: 0.3574 - val_accuracy: 0.9074\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.3114 - val_accuracy: 0.9028\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0482 - accuracy: 0.9816 - val_loss: 0.4720 - val_accuracy: 0.8993\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0476 - accuracy: 0.9834 - val_loss: 0.4892 - val_accuracy: 0.8945\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0825 - accuracy: 0.9699 - val_loss: 0.3981 - val_accuracy: 0.8900\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1035 - accuracy: 0.9631 - val_loss: 0.4835 - val_accuracy: 0.8836\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0727 - accuracy: 0.9726 - val_loss: 0.2874 - val_accuracy: 0.8988\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0612 - accuracy: 0.9782 - val_loss: 0.4862 - val_accuracy: 0.8786\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0973 - accuracy: 0.9661 - val_loss: 0.3209 - val_accuracy: 0.8935\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0688 - accuracy: 0.9770 - val_loss: 0.5092 - val_accuracy: 0.8832\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0560 - accuracy: 0.9800 - val_loss: 0.4120 - val_accuracy: 0.8942\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0863 - accuracy: 0.9691 - val_loss: 0.4362 - val_accuracy: 0.8823\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0709 - accuracy: 0.9769 - val_loss: 0.4190 - val_accuracy: 0.8875\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0675 - accuracy: 0.9761 - val_loss: 0.4427 - val_accuracy: 0.8766\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0630 - accuracy: 0.9738 - val_loss: 0.4773 - val_accuracy: 0.8923\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0455 - accuracy: 0.9830 - val_loss: 0.4593 - val_accuracy: 0.8775\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0504 - accuracy: 0.9817 - val_loss: 0.4004 - val_accuracy: 0.8969\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0525 - accuracy: 0.9799 - val_loss: 0.4665 - val_accuracy: 0.8808\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0533 - accuracy: 0.9796 - val_loss: 0.4774 - val_accuracy: 0.8857\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0505 - accuracy: 0.9813 - val_loss: 0.4545 - val_accuracy: 0.8918\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0657 - accuracy: 0.9748 - val_loss: 0.3808 - val_accuracy: 0.9077\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0541 - accuracy: 0.9854 - val_loss: 0.4689 - val_accuracy: 0.8946\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0819 - accuracy: 0.9746 - val_loss: 0.3409 - val_accuracy: 0.8882\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0734 - accuracy: 0.9732 - val_loss: 0.3803 - val_accuracy: 0.9024\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0629 - accuracy: 0.9770 - val_loss: 0.4454 - val_accuracy: 0.8905\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0590 - accuracy: 0.9781 - val_loss: 0.3066 - val_accuracy: 0.9113\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.3632 - val_accuracy: 0.8935\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.4306 - val_accuracy: 0.8882\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0668 - accuracy: 0.9740 - val_loss: 0.4508 - val_accuracy: 0.8874\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.3804 - val_accuracy: 0.9104\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.4159 - val_accuracy: 0.8966\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.4407 - val_accuracy: 0.8958\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 0.3978 - val_accuracy: 0.9095\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.4041 - val_accuracy: 0.8921\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0845 - accuracy: 0.9668 - val_loss: 0.3588 - val_accuracy: 0.8921\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0661 - accuracy: 0.9771 - val_loss: 0.3546 - val_accuracy: 0.9091\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.4727 - val_accuracy: 0.8955\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.4273 - val_accuracy: 0.8708\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0796 - accuracy: 0.9740 - val_loss: 0.3727 - val_accuracy: 0.8990\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0450 - accuracy: 0.9798 - val_loss: 0.4360 - val_accuracy: 0.8975\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0351 - accuracy: 0.9880 - val_loss: 0.5691 - val_accuracy: 0.8860\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0502 - accuracy: 0.9809 - val_loss: 0.4799 - val_accuracy: 0.8882\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0807 - accuracy: 0.9745 - val_loss: 0.3276 - val_accuracy: 0.8814\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0550 - accuracy: 0.9802 - val_loss: 0.4295 - val_accuracy: 0.9033\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0614 - accuracy: 0.9770 - val_loss: 0.4383 - val_accuracy: 0.8853\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.4344 - val_accuracy: 0.8909\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0549 - accuracy: 0.9787 - val_loss: 0.2932 - val_accuracy: 0.9140\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0648 - accuracy: 0.9741 - val_loss: 0.3167 - val_accuracy: 0.9000\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.3742 - val_accuracy: 0.9016\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.3361 - val_accuracy: 0.9101\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 0.3792 - val_accuracy: 0.9009\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0685 - accuracy: 0.9797 - val_loss: 0.3248 - val_accuracy: 0.8781\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1341 - accuracy: 0.9547 - val_loss: 0.3351 - val_accuracy: 0.9097\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0963 - accuracy: 0.9608 - val_loss: 0.3476 - val_accuracy: 0.8780\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0636 - accuracy: 0.9777 - val_loss: 0.4409 - val_accuracy: 0.8833\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.3826 - val_accuracy: 0.8973\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0580 - accuracy: 0.9798 - val_loss: 0.2922 - val_accuracy: 0.9091\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0690 - accuracy: 0.9783 - val_loss: 0.3460 - val_accuracy: 0.9071\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0444 - accuracy: 0.9825 - val_loss: 0.3496 - val_accuracy: 0.8893\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 0.3089 - val_accuracy: 0.8981\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 0.3632 - val_accuracy: 0.8997\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 0.4331 - val_accuracy: 0.8768\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0612 - accuracy: 0.9796 - val_loss: 0.4365 - val_accuracy: 0.8818\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0476 - accuracy: 0.9798 - val_loss: 0.4701 - val_accuracy: 0.8896\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.4262 - val_accuracy: 0.8911\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.3466 - val_accuracy: 0.8960\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.5135 - val_accuracy: 0.8856\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0460 - accuracy: 0.9846 - val_loss: 0.3914 - val_accuracy: 0.9125\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0514 - accuracy: 0.9828 - val_loss: 0.3848 - val_accuracy: 0.8978\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0501 - accuracy: 0.9797 - val_loss: 0.4291 - val_accuracy: 0.8915\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.4312 - val_accuracy: 0.8887\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.3611 - val_accuracy: 0.9042\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0413 - accuracy: 0.9851 - val_loss: 0.4282 - val_accuracy: 0.8990\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0295 - accuracy: 0.9881 - val_loss: 0.4285 - val_accuracy: 0.9024\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0504 - accuracy: 0.9862 - val_loss: 0.3732 - val_accuracy: 0.8875\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0589 - accuracy: 0.9755 - val_loss: 0.4055 - val_accuracy: 0.8949\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0472 - accuracy: 0.9812 - val_loss: 0.3180 - val_accuracy: 0.9012\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.3558 - val_accuracy: 0.9031\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0369 - accuracy: 0.9868 - val_loss: 0.3786 - val_accuracy: 0.8875\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 0.3458 - val_accuracy: 0.9122\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 0.3503 - val_accuracy: 0.8999\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0289 - accuracy: 0.9888 - val_loss: 0.3488 - val_accuracy: 0.8932\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.4022 - val_accuracy: 0.8909\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0451 - accuracy: 0.9832 - val_loss: 0.4203 - val_accuracy: 0.8820\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0742 - accuracy: 0.9741 - val_loss: 0.3312 - val_accuracy: 0.9144\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0376 - accuracy: 0.9871 - val_loss: 0.3506 - val_accuracy: 0.9048\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0609 - accuracy: 0.9768 - val_loss: 0.3578 - val_accuracy: 0.9015\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0473 - accuracy: 0.9818 - val_loss: 0.4550 - val_accuracy: 0.9007\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.4048 - val_accuracy: 0.8926\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.3451 - val_accuracy: 0.9054\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0576 - accuracy: 0.9835 - val_loss: 0.4208 - val_accuracy: 0.8905\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0567 - accuracy: 0.9788 - val_loss: 0.3439 - val_accuracy: 0.8973\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.4138 - val_accuracy: 0.8893\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.4504 - val_accuracy: 0.8771\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0355 - accuracy: 0.9868 - val_loss: 0.4468 - val_accuracy: 0.9045\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 0.4388 - val_accuracy: 0.8927\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.2665 - val_accuracy: 0.9250\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0643 - accuracy: 0.9791 - val_loss: 0.3075 - val_accuracy: 0.9094\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0530 - accuracy: 0.9859 - val_loss: 0.4176 - val_accuracy: 0.9016\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 0.3839 - val_accuracy: 0.9161\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0433 - accuracy: 0.9824 - val_loss: 0.4538 - val_accuracy: 0.8991\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.5437 - val_accuracy: 0.8875\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.3042 - val_accuracy: 0.9021\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0679 - accuracy: 0.9787 - val_loss: 0.3719 - val_accuracy: 0.9042\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0731 - accuracy: 0.9746 - val_loss: 0.3269 - val_accuracy: 0.9045\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 0.4457 - val_accuracy: 0.9083\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.3627 - val_accuracy: 0.9121\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0347 - accuracy: 0.9871 - val_loss: 0.3742 - val_accuracy: 0.8918\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.3833 - val_accuracy: 0.9033\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0517 - accuracy: 0.9814 - val_loss: 0.4201 - val_accuracy: 0.8939\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0485 - accuracy: 0.9784 - val_loss: 0.3760 - val_accuracy: 0.8952\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0486 - accuracy: 0.9829 - val_loss: 0.3636 - val_accuracy: 0.9131\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0575 - accuracy: 0.9772 - val_loss: 0.2717 - val_accuracy: 0.9126\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 0.3653 - val_accuracy: 0.9092\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.3112 - val_accuracy: 0.9156\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 0.3399 - val_accuracy: 0.9140\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 0.2873 - val_accuracy: 0.9190\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.2936 - val_accuracy: 0.9254\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 0.3719 - val_accuracy: 0.9131\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 0.3717 - val_accuracy: 0.9031\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.3317 - val_accuracy: 0.8963\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.3841 - val_accuracy: 0.8938\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.3171 - val_accuracy: 0.9143\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0440 - accuracy: 0.9834 - val_loss: 0.3385 - val_accuracy: 0.8996\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0541 - accuracy: 0.9809 - val_loss: 0.3423 - val_accuracy: 0.9138\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.4413 - val_accuracy: 0.8921\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0440 - accuracy: 0.9813 - val_loss: 0.4578 - val_accuracy: 0.8921\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0495 - accuracy: 0.9791 - val_loss: 0.4361 - val_accuracy: 0.8917\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.3730 - val_accuracy: 0.9080\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 0.4939 - val_accuracy: 0.9060\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.4275 - val_accuracy: 0.8884\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0455 - accuracy: 0.9819 - val_loss: 0.4602 - val_accuracy: 0.8930\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.3959 - val_accuracy: 0.8970\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.4095 - val_accuracy: 0.9159\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.5164 - val_accuracy: 0.8978\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.5059 - val_accuracy: 0.8659\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.4420 - val_accuracy: 0.8826\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.4297 - val_accuracy: 0.9000\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0546 - accuracy: 0.9797 - val_loss: 0.3574 - val_accuracy: 0.9022\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.4303 - val_accuracy: 0.9097\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.3930 - val_accuracy: 0.8939\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0688 - accuracy: 0.9771 - val_loss: 0.3472 - val_accuracy: 0.9077\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.4236 - val_accuracy: 0.8859\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0639 - accuracy: 0.9742 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.4640 - val_accuracy: 0.8888\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.4523 - val_accuracy: 0.8751\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0736 - accuracy: 0.9760 - val_loss: 0.3685 - val_accuracy: 0.8978\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.4856 - val_accuracy: 0.8930\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.3755 - val_accuracy: 0.9007\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0683 - accuracy: 0.9755 - val_loss: 0.2788 - val_accuracy: 0.9049\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0639 - accuracy: 0.9757 - val_loss: 0.3497 - val_accuracy: 0.9024\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.4121 - val_accuracy: 0.9003\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0944 - accuracy: 0.9660 - val_loss: 0.3644 - val_accuracy: 0.8930\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.3586 - val_accuracy: 0.9082\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0701 - accuracy: 0.9751 - val_loss: 0.3588 - val_accuracy: 0.9062\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 0.3360 - val_accuracy: 0.8958\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.4532 - val_accuracy: 0.9009\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0367 - accuracy: 0.9840 - val_loss: 0.4842 - val_accuracy: 0.8999\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.4220 - val_accuracy: 0.9060\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.3792 - val_accuracy: 0.8890\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0503 - accuracy: 0.9832 - val_loss: 0.3718 - val_accuracy: 0.8932\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.4467 - val_accuracy: 0.9039\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.5065 - val_accuracy: 0.8972\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.3408 - val_accuracy: 0.8940\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.3700 - val_accuracy: 0.9045\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0422 - accuracy: 0.9813 - val_loss: 0.3555 - val_accuracy: 0.9071\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0336 - accuracy: 0.9871 - val_loss: 0.4267 - val_accuracy: 0.9042\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.3639 - val_accuracy: 0.9141\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0558 - accuracy: 0.9806 - val_loss: 0.3769 - val_accuracy: 0.9030\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0369 - accuracy: 0.9886 - val_loss: 0.4789 - val_accuracy: 0.8927\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.3755 - val_accuracy: 0.9037\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.3959 - val_accuracy: 0.9074\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0308 - accuracy: 0.9891 - val_loss: 0.3593 - val_accuracy: 0.9201\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0549 - accuracy: 0.9782 - val_loss: 0.4498 - val_accuracy: 0.9021\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.4817 - val_accuracy: 0.8914\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 0.2813 - val_accuracy: 0.9225\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.2836 - val_accuracy: 0.9274\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 0.4351 - val_accuracy: 0.9060\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.4233 - val_accuracy: 0.9182\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0658 - accuracy: 0.9803 - val_loss: 0.2744 - val_accuracy: 0.9115\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0653 - accuracy: 0.9797 - val_loss: 0.3726 - val_accuracy: 0.9112\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.3672 - val_accuracy: 0.8981\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0605 - accuracy: 0.9795 - val_loss: 0.4413 - val_accuracy: 0.8888\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0521 - accuracy: 0.9805 - val_loss: 0.3059 - val_accuracy: 0.9016\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.3276 - val_accuracy: 0.9149\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.4329 - val_accuracy: 0.8972\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0534 - accuracy: 0.9784 - val_loss: 0.3315 - val_accuracy: 0.9137\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.4049 - val_accuracy: 0.9060\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0412 - accuracy: 0.9858 - val_loss: 0.4646 - val_accuracy: 0.8836\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.3389 - val_accuracy: 0.9001\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.3877 - val_accuracy: 0.9045\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0629 - accuracy: 0.9804 - val_loss: 0.3209 - val_accuracy: 0.9068\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 0.3328 - val_accuracy: 0.9204\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.3200 - val_accuracy: 0.9158\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0611 - accuracy: 0.9772 - val_loss: 0.2661 - val_accuracy: 0.9222\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0373 - accuracy: 0.9871 - val_loss: 0.3640 - val_accuracy: 0.9124\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.3891 - val_accuracy: 0.9016\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.4083 - val_accuracy: 0.8890\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.3093 - val_accuracy: 0.9220\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.4393 - val_accuracy: 0.9048\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0333 - accuracy: 0.9907 - val_loss: 0.3304 - val_accuracy: 0.9262\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.4039 - val_accuracy: 0.8929\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 0.3139 - val_accuracy: 0.9126\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.4433 - val_accuracy: 0.9060\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.4581 - val_accuracy: 0.9012\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.4390 - val_accuracy: 0.8955\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 0.3209 - val_accuracy: 0.9124\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.3510 - val_accuracy: 0.9012\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.4087 - val_accuracy: 0.9098\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.3771 - val_accuracy: 0.9101\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0481 - accuracy: 0.9795 - val_loss: 0.4488 - val_accuracy: 0.8896\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 0.3569 - val_accuracy: 0.9019\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0527 - accuracy: 0.9793 - val_loss: 0.3403 - val_accuracy: 0.8987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5UHBC4uiUn_",
        "outputId": "c9aaa0d9-24c4-4f09-d0fa-0a0096c19b24"
      },
      "source": [
        "history3 = model3.fit(Xtrain, Ytrain, batch_size =100, epochs = 500, verbose = 1, validation_data=(Xval, Yval),callbacks=checkpoint3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 7s 56ms/step - loss: 1.1418 - accuracy: 0.7265 - val_loss: 1.2512 - val_accuracy: 0.6826\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.8910 - accuracy: 0.8636 - val_loss: 1.2083 - val_accuracy: 0.7542\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7942 - accuracy: 0.8947 - val_loss: 1.1427 - val_accuracy: 0.7984\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7603 - accuracy: 0.9015 - val_loss: 1.0666 - val_accuracy: 0.8426\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.7115 - accuracy: 0.9135 - val_loss: 0.9782 - val_accuracy: 0.8347\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6696 - accuracy: 0.9194 - val_loss: 0.9019 - val_accuracy: 0.8470\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6328 - accuracy: 0.9247 - val_loss: 0.8180 - val_accuracy: 0.8641\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5990 - accuracy: 0.9292 - val_loss: 0.7406 - val_accuracy: 0.8789\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5677 - accuracy: 0.9371 - val_loss: 0.6850 - val_accuracy: 0.8969\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5672 - accuracy: 0.9240 - val_loss: 0.6447 - val_accuracy: 0.8845\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5325 - accuracy: 0.9310 - val_loss: 0.6688 - val_accuracy: 0.8632\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5178 - accuracy: 0.9297 - val_loss: 0.6446 - val_accuracy: 0.8918\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5153 - accuracy: 0.9274 - val_loss: 0.6084 - val_accuracy: 0.8827\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4640 - accuracy: 0.9403 - val_loss: 0.6204 - val_accuracy: 0.8690\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4399 - accuracy: 0.9458 - val_loss: 0.6042 - val_accuracy: 0.8815\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4391 - accuracy: 0.9346 - val_loss: 0.5639 - val_accuracy: 0.8924\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4322 - accuracy: 0.9303 - val_loss: 0.6127 - val_accuracy: 0.8674\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4011 - accuracy: 0.9430 - val_loss: 0.5294 - val_accuracy: 0.8902\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3939 - accuracy: 0.9398 - val_loss: 0.5705 - val_accuracy: 0.8868\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3742 - accuracy: 0.9427 - val_loss: 0.5806 - val_accuracy: 0.8811\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3587 - accuracy: 0.9456 - val_loss: 0.5512 - val_accuracy: 0.8990\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3413 - accuracy: 0.9473 - val_loss: 0.5859 - val_accuracy: 0.8751\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3377 - accuracy: 0.9459 - val_loss: 0.5118 - val_accuracy: 0.8902\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3115 - accuracy: 0.9550 - val_loss: 0.5308 - val_accuracy: 0.8798\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2961 - accuracy: 0.9539 - val_loss: 0.5016 - val_accuracy: 0.8981\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2881 - accuracy: 0.9553 - val_loss: 0.5213 - val_accuracy: 0.8792\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2842 - accuracy: 0.9526 - val_loss: 0.5038 - val_accuracy: 0.8829\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2979 - accuracy: 0.9417 - val_loss: 0.4784 - val_accuracy: 0.8920\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3100 - accuracy: 0.9385 - val_loss: 0.4995 - val_accuracy: 0.8735\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2916 - accuracy: 0.9445 - val_loss: 0.4175 - val_accuracy: 0.9024\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2717 - accuracy: 0.9490 - val_loss: 0.4789 - val_accuracy: 0.8876\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2666 - accuracy: 0.9436 - val_loss: 0.4918 - val_accuracy: 0.8921\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2775 - accuracy: 0.9365 - val_loss: 0.4488 - val_accuracy: 0.8924\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2547 - accuracy: 0.9462 - val_loss: 0.3824 - val_accuracy: 0.9128\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2448 - accuracy: 0.9487 - val_loss: 0.4089 - val_accuracy: 0.9031\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2380 - accuracy: 0.9513 - val_loss: 0.4010 - val_accuracy: 0.9022\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2309 - accuracy: 0.9493 - val_loss: 0.4348 - val_accuracy: 0.8866\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2234 - accuracy: 0.9498 - val_loss: 0.4086 - val_accuracy: 0.9012\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2063 - accuracy: 0.9576 - val_loss: 0.4387 - val_accuracy: 0.8753\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2284 - accuracy: 0.9444 - val_loss: 0.3214 - val_accuracy: 0.9171\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2127 - accuracy: 0.9497 - val_loss: 0.3635 - val_accuracy: 0.9095\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1941 - accuracy: 0.9545 - val_loss: 0.3088 - val_accuracy: 0.9199\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2077 - accuracy: 0.9487 - val_loss: 0.3418 - val_accuracy: 0.9104\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2007 - accuracy: 0.9511 - val_loss: 0.4110 - val_accuracy: 0.9039\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2189 - accuracy: 0.9425 - val_loss: 0.4196 - val_accuracy: 0.8579\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1993 - accuracy: 0.9521 - val_loss: 0.4137 - val_accuracy: 0.8814\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1900 - accuracy: 0.9522 - val_loss: 0.3698 - val_accuracy: 0.9027\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1807 - accuracy: 0.9549 - val_loss: 0.3512 - val_accuracy: 0.9067\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1686 - accuracy: 0.9602 - val_loss: 0.3852 - val_accuracy: 0.8926\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1622 - accuracy: 0.9619 - val_loss: 0.3230 - val_accuracy: 0.9076\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1611 - accuracy: 0.9591 - val_loss: 0.3767 - val_accuracy: 0.8979\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1664 - accuracy: 0.9576 - val_loss: 0.3173 - val_accuracy: 0.9091\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1558 - accuracy: 0.9609 - val_loss: 0.3503 - val_accuracy: 0.9025\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1623 - accuracy: 0.9585 - val_loss: 0.3356 - val_accuracy: 0.9083\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1587 - accuracy: 0.9594 - val_loss: 0.3181 - val_accuracy: 0.9094\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1573 - accuracy: 0.9570 - val_loss: 0.3351 - val_accuracy: 0.8964\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1506 - accuracy: 0.9593 - val_loss: 0.3639 - val_accuracy: 0.8866\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1530 - accuracy: 0.9577 - val_loss: 0.3379 - val_accuracy: 0.8943\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1671 - accuracy: 0.9499 - val_loss: 0.3614 - val_accuracy: 0.8821\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1441 - accuracy: 0.9625 - val_loss: 0.3557 - val_accuracy: 0.8887\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1514 - accuracy: 0.9548 - val_loss: 0.3523 - val_accuracy: 0.8905\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1915 - accuracy: 0.9420 - val_loss: 0.3021 - val_accuracy: 0.9077\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1616 - accuracy: 0.9512 - val_loss: 0.3062 - val_accuracy: 0.9143\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1440 - accuracy: 0.9573 - val_loss: 0.2973 - val_accuracy: 0.9080\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1259 - accuracy: 0.9639 - val_loss: 0.3164 - val_accuracy: 0.9103\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1400 - accuracy: 0.9588 - val_loss: 0.3179 - val_accuracy: 0.8981\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1272 - accuracy: 0.9638 - val_loss: 0.3554 - val_accuracy: 0.8987\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1162 - accuracy: 0.9697 - val_loss: 0.3035 - val_accuracy: 0.9155\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1259 - accuracy: 0.9630 - val_loss: 0.2895 - val_accuracy: 0.9104\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1338 - accuracy: 0.9605 - val_loss: 0.3097 - val_accuracy: 0.8987\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1397 - accuracy: 0.9594 - val_loss: 0.3020 - val_accuracy: 0.9091\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1453 - accuracy: 0.9570 - val_loss: 0.3516 - val_accuracy: 0.8902\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1380 - accuracy: 0.9557 - val_loss: 0.2535 - val_accuracy: 0.9281\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1317 - accuracy: 0.9594 - val_loss: 0.3395 - val_accuracy: 0.8926\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.3234 - val_accuracy: 0.8969\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1323 - accuracy: 0.9595 - val_loss: 0.3492 - val_accuracy: 0.9016\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1221 - accuracy: 0.9625 - val_loss: 0.3465 - val_accuracy: 0.9057\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1236 - accuracy: 0.9625 - val_loss: 0.3247 - val_accuracy: 0.8929\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1216 - accuracy: 0.9617 - val_loss: 0.3560 - val_accuracy: 0.9019\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1270 - accuracy: 0.9605 - val_loss: 0.3150 - val_accuracy: 0.9021\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1325 - accuracy: 0.9581 - val_loss: 0.3228 - val_accuracy: 0.8964\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1218 - accuracy: 0.9614 - val_loss: 0.3819 - val_accuracy: 0.8957\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1162 - accuracy: 0.9653 - val_loss: 0.3813 - val_accuracy: 0.8882\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1289 - accuracy: 0.9610 - val_loss: 0.3031 - val_accuracy: 0.9118\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1166 - accuracy: 0.9629 - val_loss: 0.3137 - val_accuracy: 0.9055\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1174 - accuracy: 0.9659 - val_loss: 0.3371 - val_accuracy: 0.8882\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1382 - accuracy: 0.9542 - val_loss: 0.3404 - val_accuracy: 0.8976\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1294 - accuracy: 0.9580 - val_loss: 0.3634 - val_accuracy: 0.8787\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1443 - accuracy: 0.9501 - val_loss: 0.3183 - val_accuracy: 0.8893\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1192 - accuracy: 0.9644 - val_loss: 0.3821 - val_accuracy: 0.8918\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1312 - accuracy: 0.9557 - val_loss: 0.3260 - val_accuracy: 0.9073\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1089 - accuracy: 0.9664 - val_loss: 0.3282 - val_accuracy: 0.8945\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0989 - accuracy: 0.9695 - val_loss: 0.3740 - val_accuracy: 0.8954\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1100 - accuracy: 0.9632 - val_loss: 0.3313 - val_accuracy: 0.9121\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1104 - accuracy: 0.9661 - val_loss: 0.3066 - val_accuracy: 0.9064\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1104 - accuracy: 0.9662 - val_loss: 0.3166 - val_accuracy: 0.9074\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1097 - accuracy: 0.9627 - val_loss: 0.3395 - val_accuracy: 0.9001\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1246 - accuracy: 0.9580 - val_loss: 0.3522 - val_accuracy: 0.8850\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1185 - accuracy: 0.9605 - val_loss: 0.3132 - val_accuracy: 0.9073\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1094 - accuracy: 0.9661 - val_loss: 0.2810 - val_accuracy: 0.9135\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1040 - accuracy: 0.9671 - val_loss: 0.3593 - val_accuracy: 0.9036\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1142 - accuracy: 0.9633 - val_loss: 0.3263 - val_accuracy: 0.9057\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1152 - accuracy: 0.9629 - val_loss: 0.3662 - val_accuracy: 0.8943\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1379 - accuracy: 0.9554 - val_loss: 0.3398 - val_accuracy: 0.8893\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1065 - accuracy: 0.9674 - val_loss: 0.2894 - val_accuracy: 0.9074\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1021 - accuracy: 0.9662 - val_loss: 0.3537 - val_accuracy: 0.8906\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0938 - accuracy: 0.9724 - val_loss: 0.3279 - val_accuracy: 0.9153\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1046 - accuracy: 0.9671 - val_loss: 0.3420 - val_accuracy: 0.9006\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1008 - accuracy: 0.9676 - val_loss: 0.3799 - val_accuracy: 0.9048\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1338 - accuracy: 0.9533 - val_loss: 0.3132 - val_accuracy: 0.8958\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1273 - accuracy: 0.9562 - val_loss: 0.3605 - val_accuracy: 0.8841\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1350 - accuracy: 0.9534 - val_loss: 0.3035 - val_accuracy: 0.8987\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1212 - accuracy: 0.9618 - val_loss: 0.3012 - val_accuracy: 0.9112\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0982 - accuracy: 0.9695 - val_loss: 0.2910 - val_accuracy: 0.9138\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0957 - accuracy: 0.9681 - val_loss: 0.2543 - val_accuracy: 0.9254\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0939 - accuracy: 0.9691 - val_loss: 0.3501 - val_accuracy: 0.9033\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1100 - accuracy: 0.9667 - val_loss: 0.4004 - val_accuracy: 0.8820\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0963 - accuracy: 0.9669 - val_loss: 0.3537 - val_accuracy: 0.8955\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1340 - accuracy: 0.9513 - val_loss: 0.3467 - val_accuracy: 0.8908\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1062 - accuracy: 0.9666 - val_loss: 0.3192 - val_accuracy: 0.9164\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1039 - accuracy: 0.9652 - val_loss: 0.3571 - val_accuracy: 0.8879\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1034 - accuracy: 0.9632 - val_loss: 0.3010 - val_accuracy: 0.9110\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1192 - accuracy: 0.9571 - val_loss: 0.3306 - val_accuracy: 0.8988\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.2908 - val_accuracy: 0.8973\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0931 - accuracy: 0.9704 - val_loss: 0.3635 - val_accuracy: 0.8946\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1168 - accuracy: 0.9596 - val_loss: 0.3381 - val_accuracy: 0.8887\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1244 - accuracy: 0.9551 - val_loss: 0.3171 - val_accuracy: 0.8958\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1083 - accuracy: 0.9624 - val_loss: 0.3558 - val_accuracy: 0.8955\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1051 - accuracy: 0.9625 - val_loss: 0.3519 - val_accuracy: 0.8930\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1048 - accuracy: 0.9637 - val_loss: 0.3107 - val_accuracy: 0.9097\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0983 - accuracy: 0.9676 - val_loss: 0.3187 - val_accuracy: 0.9012\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0999 - accuracy: 0.9661 - val_loss: 0.3310 - val_accuracy: 0.8997\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1088 - accuracy: 0.9627 - val_loss: 0.3550 - val_accuracy: 0.8909\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1132 - accuracy: 0.9593 - val_loss: 0.2470 - val_accuracy: 0.9118\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.3618 - val_accuracy: 0.9025\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0848 - accuracy: 0.9725 - val_loss: 0.2853 - val_accuracy: 0.9201\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0884 - accuracy: 0.9692 - val_loss: 0.3395 - val_accuracy: 0.8906\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0975 - accuracy: 0.9640 - val_loss: 0.3864 - val_accuracy: 0.8790\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.3105 - val_accuracy: 0.9138\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0752 - accuracy: 0.9779 - val_loss: 0.3682 - val_accuracy: 0.8933\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0987 - accuracy: 0.9638 - val_loss: 0.3977 - val_accuracy: 0.8802\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 0.3863 - val_accuracy: 0.8900\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0965 - accuracy: 0.9645 - val_loss: 0.2995 - val_accuracy: 0.9042\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0940 - accuracy: 0.9671 - val_loss: 0.2989 - val_accuracy: 0.9006\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.2953 - val_accuracy: 0.9058\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.3003 - val_accuracy: 0.9101\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0803 - accuracy: 0.9737 - val_loss: 0.2933 - val_accuracy: 0.9064\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0976 - accuracy: 0.9678 - val_loss: 0.3496 - val_accuracy: 0.8949\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0811 - accuracy: 0.9739 - val_loss: 0.3460 - val_accuracy: 0.9064\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.3725 - val_accuracy: 0.9024\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0946 - accuracy: 0.9661 - val_loss: 0.3503 - val_accuracy: 0.9091\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0830 - accuracy: 0.9716 - val_loss: 0.3220 - val_accuracy: 0.9057\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0797 - accuracy: 0.9743 - val_loss: 0.2782 - val_accuracy: 0.9112\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0864 - accuracy: 0.9705 - val_loss: 0.3729 - val_accuracy: 0.9021\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0792 - accuracy: 0.9728 - val_loss: 0.3774 - val_accuracy: 0.8955\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 0.2869 - val_accuracy: 0.9168\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.3138 - val_accuracy: 0.9187\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0868 - accuracy: 0.9726 - val_loss: 0.3339 - val_accuracy: 0.9057\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0850 - accuracy: 0.9706 - val_loss: 0.3651 - val_accuracy: 0.9037\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0800 - accuracy: 0.9722 - val_loss: 0.2582 - val_accuracy: 0.9259\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0817 - accuracy: 0.9712 - val_loss: 0.2702 - val_accuracy: 0.9177\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 0.3549 - val_accuracy: 0.8948\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: 0.3216 - val_accuracy: 0.9009\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 0.4225 - val_accuracy: 0.8781\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.3032 - val_accuracy: 0.9125\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0702 - accuracy: 0.9770 - val_loss: 0.3238 - val_accuracy: 0.9015\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.3078 - val_accuracy: 0.9045\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0749 - accuracy: 0.9734 - val_loss: 0.3420 - val_accuracy: 0.9000\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0919 - accuracy: 0.9683 - val_loss: 0.2789 - val_accuracy: 0.9219\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0718 - accuracy: 0.9754 - val_loss: 0.3407 - val_accuracy: 0.9025\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 0.3186 - val_accuracy: 0.8999\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0709 - accuracy: 0.9766 - val_loss: 0.3619 - val_accuracy: 0.9086\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0764 - accuracy: 0.9738 - val_loss: 0.3492 - val_accuracy: 0.8957\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.3690 - val_accuracy: 0.8973\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0787 - accuracy: 0.9732 - val_loss: 0.3442 - val_accuracy: 0.9040\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0758 - accuracy: 0.9739 - val_loss: 0.3367 - val_accuracy: 0.9101\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0659 - accuracy: 0.9792 - val_loss: 0.3296 - val_accuracy: 0.9062\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0645 - accuracy: 0.9796 - val_loss: 0.3507 - val_accuracy: 0.9043\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.4097 - val_accuracy: 0.9013\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.4293 - val_accuracy: 0.8933\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0733 - accuracy: 0.9734 - val_loss: 0.3759 - val_accuracy: 0.9030\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0722 - accuracy: 0.9764 - val_loss: 0.3398 - val_accuracy: 0.9012\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 0.3466 - val_accuracy: 0.9088\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0834 - accuracy: 0.9692 - val_loss: 0.4108 - val_accuracy: 0.8705\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0741 - accuracy: 0.9764 - val_loss: 0.3708 - val_accuracy: 0.8964\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.3287 - val_accuracy: 0.9112\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0591 - accuracy: 0.9807 - val_loss: 0.3056 - val_accuracy: 0.9182\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0600 - accuracy: 0.9803 - val_loss: 0.3224 - val_accuracy: 0.9134\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0730 - accuracy: 0.9753 - val_loss: 0.3673 - val_accuracy: 0.9024\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: 0.3183 - val_accuracy: 0.9049\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0676 - accuracy: 0.9771 - val_loss: 0.3399 - val_accuracy: 0.8894\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1068 - accuracy: 0.9618 - val_loss: 0.2895 - val_accuracy: 0.9027\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0799 - accuracy: 0.9723 - val_loss: 0.3491 - val_accuracy: 0.8920\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0689 - accuracy: 0.9745 - val_loss: 0.3053 - val_accuracy: 0.9153\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.3662 - val_accuracy: 0.9125\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.3132 - val_accuracy: 0.9131\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.3286 - val_accuracy: 0.9073\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.3315 - val_accuracy: 0.9036\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0792 - accuracy: 0.9712 - val_loss: 0.4324 - val_accuracy: 0.8640\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0804 - accuracy: 0.9700 - val_loss: 0.3462 - val_accuracy: 0.8982\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0751 - accuracy: 0.9755 - val_loss: 0.3743 - val_accuracy: 0.8902\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.3833 - val_accuracy: 0.9100\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.3461 - val_accuracy: 0.9062\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 0.3472 - val_accuracy: 0.9097\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.4364 - val_accuracy: 0.8777\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0922 - accuracy: 0.9668 - val_loss: 0.3979 - val_accuracy: 0.8868\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0784 - accuracy: 0.9734 - val_loss: 0.3536 - val_accuracy: 0.9013\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0609 - accuracy: 0.9788 - val_loss: 0.2874 - val_accuracy: 0.9147\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0566 - accuracy: 0.9814 - val_loss: 0.3761 - val_accuracy: 0.8939\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0736 - accuracy: 0.9745 - val_loss: 0.3712 - val_accuracy: 0.9009\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.3949 - val_accuracy: 0.8975\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0779 - accuracy: 0.9730 - val_loss: 0.3858 - val_accuracy: 0.8991\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 0.4546 - val_accuracy: 0.8774\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 0.3546 - val_accuracy: 0.9000\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 0.3552 - val_accuracy: 0.8827\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0721 - accuracy: 0.9751 - val_loss: 0.3327 - val_accuracy: 0.8921\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 0.2870 - val_accuracy: 0.9173\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0587 - accuracy: 0.9809 - val_loss: 0.2927 - val_accuracy: 0.9220\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0504 - accuracy: 0.9834 - val_loss: 0.3346 - val_accuracy: 0.9143\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0558 - accuracy: 0.9806 - val_loss: 0.3530 - val_accuracy: 0.9125\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.4323 - val_accuracy: 0.8949\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.3307 - val_accuracy: 0.9098\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0746 - accuracy: 0.9735 - val_loss: 0.3520 - val_accuracy: 0.9076\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0654 - accuracy: 0.9780 - val_loss: 0.3307 - val_accuracy: 0.9094\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0541 - accuracy: 0.9827 - val_loss: 0.2912 - val_accuracy: 0.9220\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.4446 - val_accuracy: 0.8885\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0759 - accuracy: 0.9756 - val_loss: 0.3708 - val_accuracy: 0.9031\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0877 - accuracy: 0.9707 - val_loss: 0.3371 - val_accuracy: 0.9101\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0862 - accuracy: 0.9681 - val_loss: 0.4297 - val_accuracy: 0.8954\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.4112 - val_accuracy: 0.8951\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 0.3292 - val_accuracy: 0.9085\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0743 - accuracy: 0.9744 - val_loss: 0.3406 - val_accuracy: 0.9094\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 0.3664 - val_accuracy: 0.9036\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.3372 - val_accuracy: 0.9146\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.3320 - val_accuracy: 0.9006\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0661 - accuracy: 0.9763 - val_loss: 0.3372 - val_accuracy: 0.9027\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0741 - accuracy: 0.9755 - val_loss: 0.2706 - val_accuracy: 0.9263\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.3255 - val_accuracy: 0.9098\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.3606 - val_accuracy: 0.8958\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.2967 - val_accuracy: 0.9183\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.3475 - val_accuracy: 0.9021\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0611 - accuracy: 0.9776 - val_loss: 0.4064 - val_accuracy: 0.8914\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0758 - accuracy: 0.9735 - val_loss: 0.4856 - val_accuracy: 0.8661\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 0.3862 - val_accuracy: 0.8936\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0626 - accuracy: 0.9806 - val_loss: 0.4376 - val_accuracy: 0.8871\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0615 - accuracy: 0.9771 - val_loss: 0.4349 - val_accuracy: 0.8940\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.3943 - val_accuracy: 0.8936\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0676 - accuracy: 0.9755 - val_loss: 0.3723 - val_accuracy: 0.9070\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0813 - accuracy: 0.9736 - val_loss: 0.4204 - val_accuracy: 0.8842\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0635 - accuracy: 0.9799 - val_loss: 0.3317 - val_accuracy: 0.9040\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.4764 - val_accuracy: 0.8583\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0976 - accuracy: 0.9640 - val_loss: 0.3110 - val_accuracy: 0.9061\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0767 - accuracy: 0.9732 - val_loss: 0.3293 - val_accuracy: 0.8993\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0831 - accuracy: 0.9710 - val_loss: 0.3259 - val_accuracy: 0.9097\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0759 - accuracy: 0.9733 - val_loss: 0.3686 - val_accuracy: 0.8951\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.3982 - val_accuracy: 0.8973\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0539 - accuracy: 0.9813 - val_loss: 0.4234 - val_accuracy: 0.8865\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0773 - accuracy: 0.9734 - val_loss: 0.3389 - val_accuracy: 0.8967\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 0.2803 - val_accuracy: 0.9129\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0686 - accuracy: 0.9777 - val_loss: 0.3355 - val_accuracy: 0.9031\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0525 - accuracy: 0.9828 - val_loss: 0.3921 - val_accuracy: 0.8921\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.3840 - val_accuracy: 0.8981\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0731 - accuracy: 0.9756 - val_loss: 0.3645 - val_accuracy: 0.8932\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0635 - accuracy: 0.9772 - val_loss: 0.3321 - val_accuracy: 0.9013\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.2924 - val_accuracy: 0.9262\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0614 - accuracy: 0.9796 - val_loss: 0.3747 - val_accuracy: 0.8976\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0464 - accuracy: 0.9842 - val_loss: 0.3545 - val_accuracy: 0.9122\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.2874 - val_accuracy: 0.9228\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0480 - accuracy: 0.9834 - val_loss: 0.3781 - val_accuracy: 0.9021\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0651 - accuracy: 0.9773 - val_loss: 0.4797 - val_accuracy: 0.8780\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0730 - accuracy: 0.9740 - val_loss: 0.4290 - val_accuracy: 0.8866\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.4069 - val_accuracy: 0.8820\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0792 - accuracy: 0.9701 - val_loss: 0.3937 - val_accuracy: 0.8939\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 0.4468 - val_accuracy: 0.8869\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0570 - accuracy: 0.9819 - val_loss: 0.4258 - val_accuracy: 0.9045\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.3942 - val_accuracy: 0.9006\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0541 - accuracy: 0.9813 - val_loss: 0.4055 - val_accuracy: 0.8948\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0752 - accuracy: 0.9747 - val_loss: 0.3643 - val_accuracy: 0.8993\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0529 - accuracy: 0.9827 - val_loss: 0.4580 - val_accuracy: 0.8728\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 0.3163 - val_accuracy: 0.9109\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0681 - accuracy: 0.9769 - val_loss: 0.3424 - val_accuracy: 0.8960\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0684 - accuracy: 0.9762 - val_loss: 0.3421 - val_accuracy: 0.8994\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 0.3205 - val_accuracy: 0.8993\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0488 - accuracy: 0.9833 - val_loss: 0.3949 - val_accuracy: 0.9031\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.3580 - val_accuracy: 0.9025\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 0.9808 - val_loss: 0.3599 - val_accuracy: 0.8997\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.3142 - val_accuracy: 0.9213\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.3143 - val_accuracy: 0.9070\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0613 - accuracy: 0.9786 - val_loss: 0.3269 - val_accuracy: 0.9177\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0541 - accuracy: 0.9807 - val_loss: 0.4012 - val_accuracy: 0.8951\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0643 - accuracy: 0.9768 - val_loss: 0.3664 - val_accuracy: 0.9037\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0557 - accuracy: 0.9813 - val_loss: 0.2867 - val_accuracy: 0.9167\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.3578 - val_accuracy: 0.8985\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.4047 - val_accuracy: 0.8891\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.3593 - val_accuracy: 0.8979\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0714 - accuracy: 0.9743 - val_loss: 0.3942 - val_accuracy: 0.8848\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 0.4391 - val_accuracy: 0.8878\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.3814 - val_accuracy: 0.8957\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0499 - accuracy: 0.9825 - val_loss: 0.3503 - val_accuracy: 0.9016\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.3368 - val_accuracy: 0.9124\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.2902 - val_accuracy: 0.9249\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.3499 - val_accuracy: 0.9168\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.3751 - val_accuracy: 0.9113\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 0.4689 - val_accuracy: 0.8729\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0870 - accuracy: 0.9700 - val_loss: 0.4355 - val_accuracy: 0.8979\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0806 - accuracy: 0.9707 - val_loss: 0.3934 - val_accuracy: 0.8854\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.3213 - val_accuracy: 0.9168\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0465 - accuracy: 0.9847 - val_loss: 0.4132 - val_accuracy: 0.8871\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0692 - accuracy: 0.9761 - val_loss: 0.3850 - val_accuracy: 0.9027\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0662 - accuracy: 0.9777 - val_loss: 0.3065 - val_accuracy: 0.9051\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.2850 - val_accuracy: 0.9168\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 0.3343 - val_accuracy: 0.9097\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0480 - accuracy: 0.9835 - val_loss: 0.4327 - val_accuracy: 0.8738\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.2978 - val_accuracy: 0.9222\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.3808 - val_accuracy: 0.8990\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.3151 - val_accuracy: 0.9121\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.3156 - val_accuracy: 0.9240\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0530 - accuracy: 0.9815 - val_loss: 0.3936 - val_accuracy: 0.8958\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.3153 - val_accuracy: 0.9134\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 0.3048 - val_accuracy: 0.9119\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0431 - accuracy: 0.9852 - val_loss: 0.3242 - val_accuracy: 0.9091\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.3264 - val_accuracy: 0.9124\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.3100 - val_accuracy: 0.9126\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.3721 - val_accuracy: 0.9022\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.3189 - val_accuracy: 0.8997\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.2658 - val_accuracy: 0.9226\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0568 - accuracy: 0.9799 - val_loss: 0.3078 - val_accuracy: 0.9177\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.3802 - val_accuracy: 0.9086\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.3475 - val_accuracy: 0.9122\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 0.3333 - val_accuracy: 0.9045\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: 0.3506 - val_accuracy: 0.9007\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0516 - accuracy: 0.9828 - val_loss: 0.5015 - val_accuracy: 0.8719\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.3376 - val_accuracy: 0.9106\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.4342 - val_accuracy: 0.8876\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0716 - accuracy: 0.9761 - val_loss: 0.3106 - val_accuracy: 0.9126\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.4197 - val_accuracy: 0.8943\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.4086 - val_accuracy: 0.8948\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 0.4051 - val_accuracy: 0.9058\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.4187 - val_accuracy: 0.8930\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.3322 - val_accuracy: 0.9153\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 0.4122 - val_accuracy: 0.8969\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0615 - accuracy: 0.9771 - val_loss: 0.3877 - val_accuracy: 0.8955\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.3321 - val_accuracy: 0.9129\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.3582 - val_accuracy: 0.9049\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.3896 - val_accuracy: 0.8802\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.4067 - val_accuracy: 0.8943\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0789 - accuracy: 0.9729 - val_loss: 0.3926 - val_accuracy: 0.8879\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0534 - accuracy: 0.9819 - val_loss: 0.4326 - val_accuracy: 0.8847\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.4326 - val_accuracy: 0.8824\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.3690 - val_accuracy: 0.9039\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.4334 - val_accuracy: 0.9000\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 0.9826 - val_loss: 0.4411 - val_accuracy: 0.8890\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 0.4316 - val_accuracy: 0.8967\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.4387 - val_accuracy: 0.9001\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.4621 - val_accuracy: 0.8973\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.3929 - val_accuracy: 0.8893\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.3590 - val_accuracy: 0.9082\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.3779 - val_accuracy: 0.8994\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0540 - accuracy: 0.9813 - val_loss: 0.3627 - val_accuracy: 0.8955\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 0.3491 - val_accuracy: 0.9083\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0485 - accuracy: 0.9838 - val_loss: 0.3436 - val_accuracy: 0.9034\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 0.3661 - val_accuracy: 0.8976\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.3702 - val_accuracy: 0.9088\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0512 - accuracy: 0.9828 - val_loss: 0.3809 - val_accuracy: 0.8961\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.4054 - val_accuracy: 0.9025\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.5030 - val_accuracy: 0.8683\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0551 - accuracy: 0.9798 - val_loss: 0.4125 - val_accuracy: 0.8935\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.5030 - val_accuracy: 0.8850\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 0.3789 - val_accuracy: 0.9065\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0443 - accuracy: 0.9836 - val_loss: 0.4050 - val_accuracy: 0.8963\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.4172 - val_accuracy: 0.9004\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0378 - accuracy: 0.9875 - val_loss: 0.3885 - val_accuracy: 0.8967\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.4414 - val_accuracy: 0.8830\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0475 - accuracy: 0.9839 - val_loss: 0.3555 - val_accuracy: 0.9109\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0494 - accuracy: 0.9819 - val_loss: 0.4488 - val_accuracy: 0.8826\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.3564 - val_accuracy: 0.9082\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.3694 - val_accuracy: 0.8978\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.4312 - val_accuracy: 0.8860\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0485 - accuracy: 0.9828 - val_loss: 0.3140 - val_accuracy: 0.9161\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0513 - accuracy: 0.9824 - val_loss: 0.3874 - val_accuracy: 0.8973\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.3514 - val_accuracy: 0.9088\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0462 - accuracy: 0.9843 - val_loss: 0.4227 - val_accuracy: 0.8820\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.4659 - val_accuracy: 0.8869\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 0.4211 - val_accuracy: 0.8933\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.3053 - val_accuracy: 0.9140\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.4016 - val_accuracy: 0.8893\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 0.9789 - val_loss: 0.4417 - val_accuracy: 0.8830\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.3816 - val_accuracy: 0.8938\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.4474 - val_accuracy: 0.8793\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 0.4164 - val_accuracy: 0.8903\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.3667 - val_accuracy: 0.9030\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0438 - accuracy: 0.9835 - val_loss: 0.3487 - val_accuracy: 0.9177\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 0.9791 - val_loss: 0.3795 - val_accuracy: 0.8915\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0557 - accuracy: 0.9809 - val_loss: 0.4177 - val_accuracy: 0.8894\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.3808 - val_accuracy: 0.8932\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 0.3378 - val_accuracy: 0.9068\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0409 - accuracy: 0.9857 - val_loss: 0.3820 - val_accuracy: 0.9065\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.4074 - val_accuracy: 0.9138\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.3651 - val_accuracy: 0.9104\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.4760 - val_accuracy: 0.8869\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.3906 - val_accuracy: 0.9070\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0640 - accuracy: 0.9768 - val_loss: 0.3388 - val_accuracy: 0.9042\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.3599 - val_accuracy: 0.9046\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 0.4397 - val_accuracy: 0.8772\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.4548 - val_accuracy: 0.8871\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.3429 - val_accuracy: 0.9098\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0443 - accuracy: 0.9849 - val_loss: 0.4216 - val_accuracy: 0.8939\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 0.3769 - val_accuracy: 0.9037\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0705 - accuracy: 0.9763 - val_loss: 0.5164 - val_accuracy: 0.8670\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0520 - accuracy: 0.9820 - val_loss: 0.4117 - val_accuracy: 0.8914\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.3684 - val_accuracy: 0.9086\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0524 - accuracy: 0.9850 - val_loss: 0.3260 - val_accuracy: 0.9073\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.3346 - val_accuracy: 0.9094\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.4436 - val_accuracy: 0.8746\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.4385 - val_accuracy: 0.8756\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.4543 - val_accuracy: 0.8668\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 0.3402 - val_accuracy: 0.9153\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.4579 - val_accuracy: 0.8723\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.3166 - val_accuracy: 0.9143\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.3496 - val_accuracy: 0.9089\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.3482 - val_accuracy: 0.9137\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.4879 - val_accuracy: 0.8792\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.4457 - val_accuracy: 0.8985\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0414 - accuracy: 0.9864 - val_loss: 0.3853 - val_accuracy: 0.8997\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0845 - accuracy: 0.9720 - val_loss: 0.4064 - val_accuracy: 0.8802\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0548 - accuracy: 0.9794 - val_loss: 0.3899 - val_accuracy: 0.8960\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.3690 - val_accuracy: 0.9115\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.3175 - val_accuracy: 0.9088\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0488 - accuracy: 0.9839 - val_loss: 0.4726 - val_accuracy: 0.8743\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0416 - accuracy: 0.9852 - val_loss: 0.3585 - val_accuracy: 0.9085\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.3928 - val_accuracy: 0.9031\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.4524 - val_accuracy: 0.8891\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.4359 - val_accuracy: 0.8909\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.4289 - val_accuracy: 0.8896\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.3413 - val_accuracy: 0.9062\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 0.4254 - val_accuracy: 0.8975\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0408 - accuracy: 0.9871 - val_loss: 0.4193 - val_accuracy: 0.9004\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.4282 - val_accuracy: 0.8954\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.3957 - val_accuracy: 0.9015\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.3974 - val_accuracy: 0.8999\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0519 - accuracy: 0.9821 - val_loss: 0.3695 - val_accuracy: 0.9004\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.4845 - val_accuracy: 0.8717\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 0.3872 - val_accuracy: 0.9040\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.3661 - val_accuracy: 0.9065\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0363 - accuracy: 0.9865 - val_loss: 0.3791 - val_accuracy: 0.9192\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 0.3485 - val_accuracy: 0.9147\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0500 - accuracy: 0.9828 - val_loss: 0.3716 - val_accuracy: 0.9057\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.3310 - val_accuracy: 0.9119\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.3605 - val_accuracy: 0.9012\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0554 - accuracy: 0.9807 - val_loss: 0.4678 - val_accuracy: 0.8795\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.4824 - val_accuracy: 0.8805\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0502 - accuracy: 0.9828 - val_loss: 0.4934 - val_accuracy: 0.8689\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.4354 - val_accuracy: 0.8859\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.4031 - val_accuracy: 0.8814\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0587 - accuracy: 0.9775 - val_loss: 0.4348 - val_accuracy: 0.9007\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0472 - accuracy: 0.9841 - val_loss: 0.3542 - val_accuracy: 0.9057\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.4320 - val_accuracy: 0.8868\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.3832 - val_accuracy: 0.9010\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.3726 - val_accuracy: 0.9033\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.3952 - val_accuracy: 0.9009\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 0.4005 - val_accuracy: 0.8993\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.3763 - val_accuracy: 0.8888\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0778 - accuracy: 0.9709 - val_loss: 0.3698 - val_accuracy: 0.8914\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0874 - accuracy: 0.9679 - val_loss: 0.3267 - val_accuracy: 0.9031\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0459 - accuracy: 0.9834 - val_loss: 0.4868 - val_accuracy: 0.8866\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.3665 - val_accuracy: 0.9027\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0588 - accuracy: 0.9791 - val_loss: 0.3268 - val_accuracy: 0.9076\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.4472 - val_accuracy: 0.8801\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0683 - accuracy: 0.9766 - val_loss: 0.3133 - val_accuracy: 0.9185\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.3048 - val_accuracy: 0.9176\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0485 - accuracy: 0.9814 - val_loss: 0.3631 - val_accuracy: 0.9141\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.3619 - val_accuracy: 0.9054\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.3165 - val_accuracy: 0.9272\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.3705 - val_accuracy: 0.9144\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0449 - accuracy: 0.9850 - val_loss: 0.3777 - val_accuracy: 0.8936\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.4869 - val_accuracy: 0.8792\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.4322 - val_accuracy: 0.8932\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0505 - accuracy: 0.9807 - val_loss: 0.4560 - val_accuracy: 0.8917\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0557 - accuracy: 0.9794 - val_loss: 0.3904 - val_accuracy: 0.9018\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0484 - accuracy: 0.9841 - val_loss: 0.3011 - val_accuracy: 0.9247\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.3146 - val_accuracy: 0.9064\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 0.3269 - val_accuracy: 0.9104\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0462 - accuracy: 0.9850 - val_loss: 0.3917 - val_accuracy: 0.9061\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.2928 - val_accuracy: 0.9198\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.3211 - val_accuracy: 0.9126\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.4528 - val_accuracy: 0.8835\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0401 - accuracy: 0.9849 - val_loss: 0.3764 - val_accuracy: 0.9057\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.4102 - val_accuracy: 0.9089\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 0.3592 - val_accuracy: 0.9022\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0443 - accuracy: 0.9833 - val_loss: 0.3732 - val_accuracy: 0.9022\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0567 - accuracy: 0.9777 - val_loss: 0.2958 - val_accuracy: 0.9193\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0360 - accuracy: 0.9872 - val_loss: 0.3835 - val_accuracy: 0.8946\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.3694 - val_accuracy: 0.9046\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0447 - accuracy: 0.9840 - val_loss: 0.5263 - val_accuracy: 0.8673\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.3990 - val_accuracy: 0.8984\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.0533 - accuracy: 0.9834 - val_loss: 0.3720 - val_accuracy: 0.9122\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0455 - accuracy: 0.9843 - val_loss: 0.4103 - val_accuracy: 0.8856\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 0.4636 - val_accuracy: 0.8935\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 0.3974 - val_accuracy: 0.8906\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.4392 - val_accuracy: 0.8787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UXt4A1FiVXX",
        "outputId": "e210606a-2a0e-4b92-8a33-4d32991fab05"
      },
      "source": [
        "history4 = model4.fit(Xtrain, Ytrain, batch_size =100, epochs = 500, verbose = 1, validation_data=(Xval, Yval),callbacks=checkpoint4)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 12s 96ms/step - loss: 1.1551 - accuracy: 0.7083 - val_loss: 1.2724 - val_accuracy: 0.5524\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.9304 - accuracy: 0.8329 - val_loss: 1.2464 - val_accuracy: 0.5644\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.8635 - accuracy: 0.8624 - val_loss: 1.2208 - val_accuracy: 0.5985\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.8182 - accuracy: 0.8755 - val_loss: 1.1941 - val_accuracy: 0.6539\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.7678 - accuracy: 0.8887 - val_loss: 1.1633 - val_accuracy: 0.6329\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.7358 - accuracy: 0.8978 - val_loss: 1.1274 - val_accuracy: 0.7185\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6879 - accuracy: 0.9083 - val_loss: 1.0935 - val_accuracy: 0.7454\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6524 - accuracy: 0.9131 - val_loss: 1.0510 - val_accuracy: 0.7685\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6303 - accuracy: 0.9186 - val_loss: 0.9940 - val_accuracy: 0.8196\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6132 - accuracy: 0.9179 - val_loss: 0.9278 - val_accuracy: 0.8091\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.5853 - accuracy: 0.9236 - val_loss: 0.8646 - val_accuracy: 0.7871\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.5880 - accuracy: 0.9151 - val_loss: 0.8163 - val_accuracy: 0.8254\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.5466 - accuracy: 0.9176 - val_loss: 0.7618 - val_accuracy: 0.8193\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.5259 - accuracy: 0.9237 - val_loss: 0.7416 - val_accuracy: 0.8414\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.5030 - accuracy: 0.9274 - val_loss: 0.6702 - val_accuracy: 0.8528\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4466 - accuracy: 0.9441 - val_loss: 0.6660 - val_accuracy: 0.8876\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4448 - accuracy: 0.9414 - val_loss: 0.6823 - val_accuracy: 0.8622\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4432 - accuracy: 0.9358 - val_loss: 0.6360 - val_accuracy: 0.8452\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4251 - accuracy: 0.9349 - val_loss: 0.6463 - val_accuracy: 0.8534\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4009 - accuracy: 0.9386 - val_loss: 0.6714 - val_accuracy: 0.8420\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4120 - accuracy: 0.9336 - val_loss: 0.6453 - val_accuracy: 0.8345\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.3983 - accuracy: 0.9285 - val_loss: 0.6111 - val_accuracy: 0.8509\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4193 - accuracy: 0.9190 - val_loss: 0.9381 - val_accuracy: 0.7756\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.4206 - accuracy: 0.9121 - val_loss: 0.7426 - val_accuracy: 0.8086\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.4142 - accuracy: 0.9162 - val_loss: 0.6462 - val_accuracy: 0.8515\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.3681 - accuracy: 0.9246 - val_loss: 0.6347 - val_accuracy: 0.8335\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.3400 - accuracy: 0.9350 - val_loss: 0.6934 - val_accuracy: 0.8251\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.3305 - accuracy: 0.9378 - val_loss: 0.6657 - val_accuracy: 0.8476\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.3011 - accuracy: 0.9421 - val_loss: 0.7073 - val_accuracy: 0.8417\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.3104 - accuracy: 0.9369 - val_loss: 0.7239 - val_accuracy: 0.8423\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2943 - accuracy: 0.9398 - val_loss: 0.8353 - val_accuracy: 0.7789\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2970 - accuracy: 0.9409 - val_loss: 0.7531 - val_accuracy: 0.8085\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2767 - accuracy: 0.9431 - val_loss: 0.6707 - val_accuracy: 0.8381\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2453 - accuracy: 0.9532 - val_loss: 0.5664 - val_accuracy: 0.8653\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2855 - accuracy: 0.9359 - val_loss: 0.6570 - val_accuracy: 0.8601\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2457 - accuracy: 0.9487 - val_loss: 0.6805 - val_accuracy: 0.8472\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2474 - accuracy: 0.9465 - val_loss: 0.5850 - val_accuracy: 0.8412\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.2480 - accuracy: 0.9426 - val_loss: 0.6217 - val_accuracy: 0.8455\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.2403 - accuracy: 0.9432 - val_loss: 0.6198 - val_accuracy: 0.8445\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2564 - accuracy: 0.9368 - val_loss: 0.7011 - val_accuracy: 0.8201\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2249 - accuracy: 0.9467 - val_loss: 0.4395 - val_accuracy: 0.8746\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2369 - accuracy: 0.9427 - val_loss: 0.4384 - val_accuracy: 0.8763\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1974 - accuracy: 0.9570 - val_loss: 0.5275 - val_accuracy: 0.8384\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2100 - accuracy: 0.9503 - val_loss: 0.4445 - val_accuracy: 0.8711\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.2196 - accuracy: 0.9439 - val_loss: 0.6128 - val_accuracy: 0.8199\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2110 - accuracy: 0.9477 - val_loss: 0.6176 - val_accuracy: 0.8106\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2247 - accuracy: 0.9406 - val_loss: 0.6569 - val_accuracy: 0.7905\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2201 - accuracy: 0.9431 - val_loss: 0.5247 - val_accuracy: 0.8472\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1907 - accuracy: 0.9478 - val_loss: 0.5578 - val_accuracy: 0.8522\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2041 - accuracy: 0.9428 - val_loss: 0.5005 - val_accuracy: 0.8756\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1672 - accuracy: 0.9573 - val_loss: 0.4311 - val_accuracy: 0.8737\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2125 - accuracy: 0.9420 - val_loss: 0.4719 - val_accuracy: 0.8519\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.2034 - accuracy: 0.9426 - val_loss: 0.4818 - val_accuracy: 0.8653\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1879 - accuracy: 0.9481 - val_loss: 0.5261 - val_accuracy: 0.8499\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1842 - accuracy: 0.9485 - val_loss: 0.5050 - val_accuracy: 0.8522\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1748 - accuracy: 0.9525 - val_loss: 0.5204 - val_accuracy: 0.8624\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1654 - accuracy: 0.9546 - val_loss: 0.6339 - val_accuracy: 0.8475\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1818 - accuracy: 0.9428 - val_loss: 0.6798 - val_accuracy: 0.7996\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1685 - accuracy: 0.9531 - val_loss: 0.4867 - val_accuracy: 0.8670\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1719 - accuracy: 0.9493 - val_loss: 0.4581 - val_accuracy: 0.8692\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1762 - accuracy: 0.9430 - val_loss: 0.5082 - val_accuracy: 0.8568\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1828 - accuracy: 0.9412 - val_loss: 0.4981 - val_accuracy: 0.8382\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1848 - accuracy: 0.9434 - val_loss: 0.4018 - val_accuracy: 0.8817\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1789 - accuracy: 0.9425 - val_loss: 0.4537 - val_accuracy: 0.8683\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1784 - accuracy: 0.9428 - val_loss: 0.6553 - val_accuracy: 0.7702\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1972 - accuracy: 0.9336 - val_loss: 0.6441 - val_accuracy: 0.8329\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1593 - accuracy: 0.9541 - val_loss: 0.5301 - val_accuracy: 0.8528\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1646 - accuracy: 0.9463 - val_loss: 0.4680 - val_accuracy: 0.8658\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1481 - accuracy: 0.9562 - val_loss: 0.5093 - val_accuracy: 0.8549\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1483 - accuracy: 0.9548 - val_loss: 0.4303 - val_accuracy: 0.8757\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1576 - accuracy: 0.9504 - val_loss: 0.4724 - val_accuracy: 0.8606\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1682 - accuracy: 0.9437 - val_loss: 0.5629 - val_accuracy: 0.8406\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1646 - accuracy: 0.9459 - val_loss: 0.4766 - val_accuracy: 0.8589\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1749 - accuracy: 0.9409 - val_loss: 0.5044 - val_accuracy: 0.8577\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1583 - accuracy: 0.9515 - val_loss: 0.4440 - val_accuracy: 0.8487\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1716 - accuracy: 0.9417 - val_loss: 0.4749 - val_accuracy: 0.8518\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1786 - accuracy: 0.9350 - val_loss: 0.5401 - val_accuracy: 0.8375\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1990 - accuracy: 0.9311 - val_loss: 0.4386 - val_accuracy: 0.8481\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1873 - accuracy: 0.9352 - val_loss: 0.5310 - val_accuracy: 0.8220\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1713 - accuracy: 0.9445 - val_loss: 0.4660 - val_accuracy: 0.8449\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1729 - accuracy: 0.9373 - val_loss: 0.4522 - val_accuracy: 0.8594\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1726 - accuracy: 0.9399 - val_loss: 0.4954 - val_accuracy: 0.8509\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1421 - accuracy: 0.9509 - val_loss: 0.5270 - val_accuracy: 0.8357\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1672 - accuracy: 0.9423 - val_loss: 0.4020 - val_accuracy: 0.8768\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1613 - accuracy: 0.9460 - val_loss: 0.4512 - val_accuracy: 0.8618\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1429 - accuracy: 0.9500 - val_loss: 0.5583 - val_accuracy: 0.8504\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1440 - accuracy: 0.9520 - val_loss: 0.5351 - val_accuracy: 0.8375\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1326 - accuracy: 0.9565 - val_loss: 0.5610 - val_accuracy: 0.8485\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.4648 - val_accuracy: 0.8699\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1362 - accuracy: 0.9496 - val_loss: 0.5536 - val_accuracy: 0.8625\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1125 - accuracy: 0.9611 - val_loss: 0.5092 - val_accuracy: 0.8577\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1052 - accuracy: 0.9676 - val_loss: 0.6958 - val_accuracy: 0.8188\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1439 - accuracy: 0.9523 - val_loss: 0.5876 - val_accuracy: 0.8045\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1386 - accuracy: 0.9540 - val_loss: 0.5813 - val_accuracy: 0.8338\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1357 - accuracy: 0.9540 - val_loss: 0.5315 - val_accuracy: 0.8469\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1414 - accuracy: 0.9510 - val_loss: 0.6111 - val_accuracy: 0.8024\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1707 - accuracy: 0.9428 - val_loss: 0.4444 - val_accuracy: 0.8513\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1643 - accuracy: 0.9449 - val_loss: 0.5547 - val_accuracy: 0.8296\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1450 - accuracy: 0.9454 - val_loss: 0.4158 - val_accuracy: 0.8643\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1393 - accuracy: 0.9525 - val_loss: 0.4261 - val_accuracy: 0.8485\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1279 - accuracy: 0.9587 - val_loss: 0.5722 - val_accuracy: 0.8332\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1491 - accuracy: 0.9458 - val_loss: 0.4939 - val_accuracy: 0.8594\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1198 - accuracy: 0.9577 - val_loss: 0.4471 - val_accuracy: 0.8607\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1417 - accuracy: 0.9473 - val_loss: 0.4905 - val_accuracy: 0.8625\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1241 - accuracy: 0.9577 - val_loss: 0.4690 - val_accuracy: 0.8582\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1217 - accuracy: 0.9588 - val_loss: 0.4977 - val_accuracy: 0.8698\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0975 - accuracy: 0.9653 - val_loss: 0.4817 - val_accuracy: 0.8504\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1181 - accuracy: 0.9586 - val_loss: 0.4184 - val_accuracy: 0.8710\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.4821 - val_accuracy: 0.8466\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1334 - accuracy: 0.9505 - val_loss: 0.6260 - val_accuracy: 0.8350\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1359 - accuracy: 0.9494 - val_loss: 0.5541 - val_accuracy: 0.8396\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1307 - accuracy: 0.9542 - val_loss: 0.5233 - val_accuracy: 0.8521\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1014 - accuracy: 0.9675 - val_loss: 0.4906 - val_accuracy: 0.8711\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1153 - accuracy: 0.9594 - val_loss: 0.4193 - val_accuracy: 0.8668\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1112 - accuracy: 0.9594 - val_loss: 0.5335 - val_accuracy: 0.8527\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1215 - accuracy: 0.9561 - val_loss: 0.3961 - val_accuracy: 0.8866\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1050 - accuracy: 0.9648 - val_loss: 0.4400 - val_accuracy: 0.8765\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0957 - accuracy: 0.9649 - val_loss: 0.4816 - val_accuracy: 0.8696\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1120 - accuracy: 0.9622 - val_loss: 0.4723 - val_accuracy: 0.8676\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1247 - accuracy: 0.9544 - val_loss: 0.5624 - val_accuracy: 0.8406\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1238 - accuracy: 0.9571 - val_loss: 0.5294 - val_accuracy: 0.8278\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1102 - accuracy: 0.9599 - val_loss: 0.5115 - val_accuracy: 0.8509\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1019 - accuracy: 0.9688 - val_loss: 0.4234 - val_accuracy: 0.8781\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1072 - accuracy: 0.9616 - val_loss: 0.5920 - val_accuracy: 0.8500\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1215 - accuracy: 0.9555 - val_loss: 0.4311 - val_accuracy: 0.8815\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1026 - accuracy: 0.9625 - val_loss: 0.5321 - val_accuracy: 0.8473\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1067 - accuracy: 0.9594 - val_loss: 0.5322 - val_accuracy: 0.8318\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1631 - accuracy: 0.9368 - val_loss: 0.4298 - val_accuracy: 0.8628\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1142 - accuracy: 0.9567 - val_loss: 0.4827 - val_accuracy: 0.8692\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1013 - accuracy: 0.9630 - val_loss: 0.5452 - val_accuracy: 0.8644\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1042 - accuracy: 0.9620 - val_loss: 0.5905 - val_accuracy: 0.8424\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1128 - accuracy: 0.9564 - val_loss: 0.5188 - val_accuracy: 0.8589\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1151 - accuracy: 0.9596 - val_loss: 0.4634 - val_accuracy: 0.8728\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1184 - accuracy: 0.9583 - val_loss: 0.6525 - val_accuracy: 0.8332\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1091 - accuracy: 0.9636 - val_loss: 0.4492 - val_accuracy: 0.8804\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1334 - accuracy: 0.9516 - val_loss: 0.4014 - val_accuracy: 0.8719\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1268 - accuracy: 0.9538 - val_loss: 0.4779 - val_accuracy: 0.8679\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1178 - accuracy: 0.9592 - val_loss: 0.6600 - val_accuracy: 0.8473\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1150 - accuracy: 0.9582 - val_loss: 0.5486 - val_accuracy: 0.8417\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1280 - accuracy: 0.9543 - val_loss: 0.4396 - val_accuracy: 0.8637\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0981 - accuracy: 0.9662 - val_loss: 0.4739 - val_accuracy: 0.8646\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1453 - accuracy: 0.9485 - val_loss: 0.5685 - val_accuracy: 0.8351\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1347 - accuracy: 0.9513 - val_loss: 0.5297 - val_accuracy: 0.8329\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1264 - accuracy: 0.9512 - val_loss: 0.6392 - val_accuracy: 0.8293\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0989 - accuracy: 0.9681 - val_loss: 0.5492 - val_accuracy: 0.8580\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1042 - accuracy: 0.9621 - val_loss: 0.4906 - val_accuracy: 0.8631\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1025 - accuracy: 0.9620 - val_loss: 0.5856 - val_accuracy: 0.8432\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1220 - accuracy: 0.9547 - val_loss: 0.4272 - val_accuracy: 0.8625\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1142 - accuracy: 0.9630 - val_loss: 0.6429 - val_accuracy: 0.8040\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1289 - accuracy: 0.9550 - val_loss: 0.4034 - val_accuracy: 0.8603\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.5317 - val_accuracy: 0.8649\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0964 - accuracy: 0.9650 - val_loss: 0.5148 - val_accuracy: 0.8699\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1067 - accuracy: 0.9592 - val_loss: 0.5903 - val_accuracy: 0.8436\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1225 - accuracy: 0.9575 - val_loss: 0.6214 - val_accuracy: 0.8307\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1203 - accuracy: 0.9553 - val_loss: 0.5499 - val_accuracy: 0.8460\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.5643 - val_accuracy: 0.8427\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1206 - accuracy: 0.9561 - val_loss: 0.4909 - val_accuracy: 0.8615\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1140 - accuracy: 0.9579 - val_loss: 0.7123 - val_accuracy: 0.8158\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1543 - accuracy: 0.9417 - val_loss: 0.6014 - val_accuracy: 0.8318\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1123 - accuracy: 0.9569 - val_loss: 0.5488 - val_accuracy: 0.8616\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1058 - accuracy: 0.9599 - val_loss: 0.6047 - val_accuracy: 0.8235\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1090 - accuracy: 0.9615 - val_loss: 0.6151 - val_accuracy: 0.8363\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0993 - accuracy: 0.9672 - val_loss: 0.5536 - val_accuracy: 0.8594\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1116 - accuracy: 0.9590 - val_loss: 0.5010 - val_accuracy: 0.8442\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0928 - accuracy: 0.9642 - val_loss: 0.5726 - val_accuracy: 0.8402\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0969 - accuracy: 0.9640 - val_loss: 0.6274 - val_accuracy: 0.8347\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0860 - accuracy: 0.9690 - val_loss: 0.6180 - val_accuracy: 0.8549\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1459 - accuracy: 0.9450 - val_loss: 0.5058 - val_accuracy: 0.8494\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1163 - accuracy: 0.9550 - val_loss: 0.5490 - val_accuracy: 0.8397\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0920 - accuracy: 0.9680 - val_loss: 0.6837 - val_accuracy: 0.8228\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1065 - accuracy: 0.9589 - val_loss: 0.4680 - val_accuracy: 0.8705\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0957 - accuracy: 0.9671 - val_loss: 0.4656 - val_accuracy: 0.8564\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1055 - accuracy: 0.9602 - val_loss: 0.5472 - val_accuracy: 0.8327\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1000 - accuracy: 0.9644 - val_loss: 0.5101 - val_accuracy: 0.8628\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1089 - accuracy: 0.9617 - val_loss: 0.4586 - val_accuracy: 0.8686\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0920 - accuracy: 0.9665 - val_loss: 0.5878 - val_accuracy: 0.8506\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.8263 - val_accuracy: 0.8097\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0995 - accuracy: 0.9647 - val_loss: 0.6161 - val_accuracy: 0.8533\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0765 - accuracy: 0.9725 - val_loss: 0.6600 - val_accuracy: 0.8411\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0766 - accuracy: 0.9731 - val_loss: 0.6446 - val_accuracy: 0.8427\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1200 - accuracy: 0.9550 - val_loss: 0.5614 - val_accuracy: 0.8519\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1058 - accuracy: 0.9598 - val_loss: 0.4543 - val_accuracy: 0.8665\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0965 - accuracy: 0.9619 - val_loss: 0.5834 - val_accuracy: 0.8406\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1153 - accuracy: 0.9547 - val_loss: 0.6492 - val_accuracy: 0.8205\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0942 - accuracy: 0.9642 - val_loss: 0.4995 - val_accuracy: 0.8592\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0716 - accuracy: 0.9718 - val_loss: 0.5717 - val_accuracy: 0.8536\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0885 - accuracy: 0.9665 - val_loss: 0.5246 - val_accuracy: 0.8549\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0811 - accuracy: 0.9696 - val_loss: 0.5368 - val_accuracy: 0.8616\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1036 - accuracy: 0.9604 - val_loss: 0.6376 - val_accuracy: 0.8374\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1222 - accuracy: 0.9543 - val_loss: 0.5474 - val_accuracy: 0.8411\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1138 - accuracy: 0.9557 - val_loss: 0.5908 - val_accuracy: 0.8256\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0944 - accuracy: 0.9690 - val_loss: 0.5709 - val_accuracy: 0.8388\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0990 - accuracy: 0.9608 - val_loss: 0.5112 - val_accuracy: 0.8646\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0836 - accuracy: 0.9681 - val_loss: 0.5129 - val_accuracy: 0.8635\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1119 - accuracy: 0.9585 - val_loss: 0.5957 - val_accuracy: 0.8357\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1523 - accuracy: 0.9456 - val_loss: 0.5969 - val_accuracy: 0.8406\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0952 - accuracy: 0.9661 - val_loss: 0.4124 - val_accuracy: 0.8744\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0831 - accuracy: 0.9708 - val_loss: 0.5319 - val_accuracy: 0.8539\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0880 - accuracy: 0.9685 - val_loss: 0.5191 - val_accuracy: 0.8524\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0851 - accuracy: 0.9694 - val_loss: 0.4025 - val_accuracy: 0.8722\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1117 - accuracy: 0.9588 - val_loss: 0.4950 - val_accuracy: 0.8536\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0931 - accuracy: 0.9669 - val_loss: 0.5023 - val_accuracy: 0.8601\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0765 - accuracy: 0.9694 - val_loss: 0.4627 - val_accuracy: 0.8494\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0892 - accuracy: 0.9684 - val_loss: 0.4389 - val_accuracy: 0.8766\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0925 - accuracy: 0.9646 - val_loss: 0.4581 - val_accuracy: 0.8698\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0830 - accuracy: 0.9666 - val_loss: 0.5603 - val_accuracy: 0.8500\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0996 - accuracy: 0.9649 - val_loss: 0.5064 - val_accuracy: 0.8504\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0978 - accuracy: 0.9624 - val_loss: 0.4838 - val_accuracy: 0.8521\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0878 - accuracy: 0.9695 - val_loss: 0.4809 - val_accuracy: 0.8795\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0919 - accuracy: 0.9665 - val_loss: 0.4410 - val_accuracy: 0.8784\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.5416 - val_accuracy: 0.8622\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0656 - accuracy: 0.9742 - val_loss: 0.6722 - val_accuracy: 0.8491\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 0.5947 - val_accuracy: 0.8490\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0867 - accuracy: 0.9723 - val_loss: 0.4966 - val_accuracy: 0.8567\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0883 - accuracy: 0.9685 - val_loss: 0.4552 - val_accuracy: 0.8591\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0914 - accuracy: 0.9656 - val_loss: 0.6759 - val_accuracy: 0.8091\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0761 - accuracy: 0.9736 - val_loss: 0.5318 - val_accuracy: 0.8609\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.5008 - val_accuracy: 0.8533\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0783 - accuracy: 0.9688 - val_loss: 0.4854 - val_accuracy: 0.8679\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0653 - accuracy: 0.9769 - val_loss: 0.4519 - val_accuracy: 0.8876\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0683 - accuracy: 0.9746 - val_loss: 0.5392 - val_accuracy: 0.8650\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0786 - accuracy: 0.9709 - val_loss: 0.5473 - val_accuracy: 0.8692\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0894 - accuracy: 0.9672 - val_loss: 0.5528 - val_accuracy: 0.8460\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1096 - accuracy: 0.9606 - val_loss: 0.5351 - val_accuracy: 0.8546\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0928 - accuracy: 0.9691 - val_loss: 0.6318 - val_accuracy: 0.8393\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1487 - accuracy: 0.9374 - val_loss: 0.4593 - val_accuracy: 0.8536\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1209 - accuracy: 0.9540 - val_loss: 0.4136 - val_accuracy: 0.8734\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0977 - accuracy: 0.9640 - val_loss: 0.5227 - val_accuracy: 0.8702\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0724 - accuracy: 0.9740 - val_loss: 0.4991 - val_accuracy: 0.8664\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1242 - accuracy: 0.9544 - val_loss: 0.5390 - val_accuracy: 0.8464\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0997 - accuracy: 0.9621 - val_loss: 0.5688 - val_accuracy: 0.8402\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1089 - accuracy: 0.9576 - val_loss: 0.5570 - val_accuracy: 0.8622\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 0.5884 - val_accuracy: 0.8400\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0885 - accuracy: 0.9685 - val_loss: 0.5873 - val_accuracy: 0.8442\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0727 - accuracy: 0.9750 - val_loss: 0.5063 - val_accuracy: 0.8580\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0708 - accuracy: 0.9729 - val_loss: 0.5790 - val_accuracy: 0.8393\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0952 - accuracy: 0.9649 - val_loss: 0.5895 - val_accuracy: 0.8500\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.5608 - val_accuracy: 0.8405\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0840 - accuracy: 0.9710 - val_loss: 0.5958 - val_accuracy: 0.8567\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0810 - accuracy: 0.9697 - val_loss: 0.5890 - val_accuracy: 0.8435\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0668 - accuracy: 0.9739 - val_loss: 0.6979 - val_accuracy: 0.8442\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0703 - accuracy: 0.9736 - val_loss: 0.6188 - val_accuracy: 0.8490\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.5769 - val_accuracy: 0.8289\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1050 - accuracy: 0.9638 - val_loss: 0.4526 - val_accuracy: 0.8603\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0805 - accuracy: 0.9719 - val_loss: 0.4629 - val_accuracy: 0.8589\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0712 - accuracy: 0.9752 - val_loss: 0.4744 - val_accuracy: 0.8750\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.5262 - val_accuracy: 0.8699\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0800 - accuracy: 0.9698 - val_loss: 0.5385 - val_accuracy: 0.8717\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0866 - accuracy: 0.9677 - val_loss: 0.5982 - val_accuracy: 0.8466\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.4835 - val_accuracy: 0.8567\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0709 - accuracy: 0.9750 - val_loss: 0.5280 - val_accuracy: 0.8609\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0697 - accuracy: 0.9751 - val_loss: 0.5609 - val_accuracy: 0.8516\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0846 - accuracy: 0.9668 - val_loss: 0.5476 - val_accuracy: 0.8482\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0793 - accuracy: 0.9703 - val_loss: 0.5276 - val_accuracy: 0.8577\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0657 - accuracy: 0.9763 - val_loss: 0.4783 - val_accuracy: 0.8722\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0828 - accuracy: 0.9673 - val_loss: 0.7285 - val_accuracy: 0.8260\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.5484 - val_accuracy: 0.8438\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1172 - accuracy: 0.9576 - val_loss: 0.4983 - val_accuracy: 0.8427\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0756 - accuracy: 0.9718 - val_loss: 0.5324 - val_accuracy: 0.8499\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0681 - accuracy: 0.9748 - val_loss: 0.5155 - val_accuracy: 0.8595\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0627 - accuracy: 0.9786 - val_loss: 0.5683 - val_accuracy: 0.8624\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0950 - accuracy: 0.9665 - val_loss: 0.4770 - val_accuracy: 0.8429\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0879 - accuracy: 0.9692 - val_loss: 0.4435 - val_accuracy: 0.8818\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0912 - accuracy: 0.9651 - val_loss: 0.4972 - val_accuracy: 0.8598\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.5875 - val_accuracy: 0.8577\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 0.7373 - val_accuracy: 0.8443\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.5993 - val_accuracy: 0.8469\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0710 - accuracy: 0.9740 - val_loss: 0.5303 - val_accuracy: 0.8588\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 0.4513 - val_accuracy: 0.8644\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: 0.4312 - val_accuracy: 0.8807\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0746 - accuracy: 0.9732 - val_loss: 0.4945 - val_accuracy: 0.8592\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0879 - accuracy: 0.9670 - val_loss: 0.5687 - val_accuracy: 0.8555\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0906 - accuracy: 0.9663 - val_loss: 0.5341 - val_accuracy: 0.8430\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0671 - accuracy: 0.9754 - val_loss: 0.6467 - val_accuracy: 0.8348\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0837 - accuracy: 0.9711 - val_loss: 0.5174 - val_accuracy: 0.8613\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0846 - accuracy: 0.9690 - val_loss: 0.4758 - val_accuracy: 0.8687\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.6277 - val_accuracy: 0.8475\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.5920 - val_accuracy: 0.8668\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 0.5336 - val_accuracy: 0.8664\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0665 - accuracy: 0.9733 - val_loss: 0.4790 - val_accuracy: 0.8844\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.5855 - val_accuracy: 0.8545\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0530 - accuracy: 0.9807 - val_loss: 0.5981 - val_accuracy: 0.8634\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.7048 - val_accuracy: 0.8519\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0563 - accuracy: 0.9787 - val_loss: 0.5356 - val_accuracy: 0.8613\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0615 - accuracy: 0.9777 - val_loss: 0.5330 - val_accuracy: 0.8466\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0828 - accuracy: 0.9709 - val_loss: 0.4870 - val_accuracy: 0.8539\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0702 - accuracy: 0.9760 - val_loss: 0.5901 - val_accuracy: 0.8543\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0717 - accuracy: 0.9758 - val_loss: 0.5350 - val_accuracy: 0.8687\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0524 - accuracy: 0.9801 - val_loss: 0.6863 - val_accuracy: 0.8540\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.6625 - val_accuracy: 0.8176\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0917 - accuracy: 0.9655 - val_loss: 0.6145 - val_accuracy: 0.8661\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0647 - accuracy: 0.9738 - val_loss: 0.7335 - val_accuracy: 0.8266\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0842 - accuracy: 0.9706 - val_loss: 0.6055 - val_accuracy: 0.8554\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 0.6706 - val_accuracy: 0.8448\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0814 - accuracy: 0.9701 - val_loss: 0.5635 - val_accuracy: 0.8388\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0766 - accuracy: 0.9706 - val_loss: 0.5715 - val_accuracy: 0.8606\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0646 - accuracy: 0.9767 - val_loss: 0.5664 - val_accuracy: 0.8616\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.6333 - val_accuracy: 0.8417\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0833 - accuracy: 0.9679 - val_loss: 0.5032 - val_accuracy: 0.8628\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0690 - accuracy: 0.9747 - val_loss: 0.5442 - val_accuracy: 0.8744\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0701 - accuracy: 0.9765 - val_loss: 0.5447 - val_accuracy: 0.8497\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0716 - accuracy: 0.9757 - val_loss: 0.5246 - val_accuracy: 0.8537\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0782 - accuracy: 0.9704 - val_loss: 0.6875 - val_accuracy: 0.8080\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0544 - accuracy: 0.9790 - val_loss: 0.5956 - val_accuracy: 0.8677\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0585 - accuracy: 0.9777 - val_loss: 0.6370 - val_accuracy: 0.8436\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0864 - accuracy: 0.9693 - val_loss: 0.4511 - val_accuracy: 0.8769\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0633 - accuracy: 0.9762 - val_loss: 0.5017 - val_accuracy: 0.8698\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0703 - accuracy: 0.9726 - val_loss: 0.5866 - val_accuracy: 0.8609\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0793 - accuracy: 0.9724 - val_loss: 0.5379 - val_accuracy: 0.8632\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0752 - accuracy: 0.9726 - val_loss: 0.6809 - val_accuracy: 0.8195\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0966 - accuracy: 0.9646 - val_loss: 0.4657 - val_accuracy: 0.8699\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0726 - accuracy: 0.9738 - val_loss: 0.6254 - val_accuracy: 0.8497\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.5991 - val_accuracy: 0.8533\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0589 - accuracy: 0.9795 - val_loss: 0.4653 - val_accuracy: 0.8634\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0804 - accuracy: 0.9684 - val_loss: 0.4449 - val_accuracy: 0.8723\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0604 - accuracy: 0.9775 - val_loss: 0.6153 - val_accuracy: 0.8565\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.5792 - val_accuracy: 0.8476\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1116 - accuracy: 0.9572 - val_loss: 0.6060 - val_accuracy: 0.8435\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0916 - accuracy: 0.9664 - val_loss: 0.5355 - val_accuracy: 0.8558\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0577 - accuracy: 0.9775 - val_loss: 0.5322 - val_accuracy: 0.8717\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0581 - accuracy: 0.9771 - val_loss: 0.5947 - val_accuracy: 0.8595\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0867 - accuracy: 0.9686 - val_loss: 0.6538 - val_accuracy: 0.8379\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.5870 - val_accuracy: 0.8649\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0604 - accuracy: 0.9763 - val_loss: 0.5673 - val_accuracy: 0.8546\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0685 - accuracy: 0.9760 - val_loss: 0.7320 - val_accuracy: 0.8147\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0854 - accuracy: 0.9694 - val_loss: 0.4673 - val_accuracy: 0.8667\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0678 - accuracy: 0.9791 - val_loss: 0.5220 - val_accuracy: 0.8787\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0381 - accuracy: 0.9856 - val_loss: 0.6297 - val_accuracy: 0.8674\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.5783 - val_accuracy: 0.8705\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0447 - accuracy: 0.9845 - val_loss: 0.6234 - val_accuracy: 0.8539\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0443 - accuracy: 0.9836 - val_loss: 0.4807 - val_accuracy: 0.8723\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0492 - accuracy: 0.9830 - val_loss: 0.6016 - val_accuracy: 0.8583\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.5680 - val_accuracy: 0.8494\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.6014 - val_accuracy: 0.8772\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0571 - accuracy: 0.9796 - val_loss: 0.4921 - val_accuracy: 0.8500\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1581 - accuracy: 0.9436 - val_loss: 0.4788 - val_accuracy: 0.8424\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0850 - accuracy: 0.9716 - val_loss: 0.5797 - val_accuracy: 0.8240\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1036 - accuracy: 0.9622 - val_loss: 0.6052 - val_accuracy: 0.8304\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0751 - accuracy: 0.9726 - val_loss: 0.4587 - val_accuracy: 0.8847\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.5122 - val_accuracy: 0.8756\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0820 - accuracy: 0.9730 - val_loss: 0.6428 - val_accuracy: 0.8353\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0906 - accuracy: 0.9693 - val_loss: 0.5246 - val_accuracy: 0.8472\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0482 - accuracy: 0.9823 - val_loss: 0.5046 - val_accuracy: 0.8674\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.4981 - val_accuracy: 0.8713\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.5419 - val_accuracy: 0.8558\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.5470 - val_accuracy: 0.8637\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0594 - accuracy: 0.9790 - val_loss: 0.5478 - val_accuracy: 0.8606\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.6390 - val_accuracy: 0.8399\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0449 - accuracy: 0.9843 - val_loss: 0.6070 - val_accuracy: 0.8543\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.4885 - val_accuracy: 0.8705\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0459 - accuracy: 0.9843 - val_loss: 0.6576 - val_accuracy: 0.8500\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.6882 - val_accuracy: 0.8397\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0591 - accuracy: 0.9777 - val_loss: 0.7641 - val_accuracy: 0.8290\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0657 - accuracy: 0.9772 - val_loss: 0.5289 - val_accuracy: 0.8656\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0738 - accuracy: 0.9757 - val_loss: 0.5558 - val_accuracy: 0.8516\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1055 - accuracy: 0.9591 - val_loss: 0.5265 - val_accuracy: 0.8674\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0740 - accuracy: 0.9769 - val_loss: 0.4797 - val_accuracy: 0.8591\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 0.6248 - val_accuracy: 0.8448\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 0.6209 - val_accuracy: 0.8493\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.6337 - val_accuracy: 0.8557\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0514 - accuracy: 0.9827 - val_loss: 0.6386 - val_accuracy: 0.8196\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 0.4956 - val_accuracy: 0.8607\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 0.6573 - val_accuracy: 0.8484\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0680 - accuracy: 0.9757 - val_loss: 0.6701 - val_accuracy: 0.8478\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0572 - accuracy: 0.9768 - val_loss: 0.6033 - val_accuracy: 0.8564\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0608 - accuracy: 0.9787 - val_loss: 0.5290 - val_accuracy: 0.8628\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0668 - accuracy: 0.9782 - val_loss: 0.5974 - val_accuracy: 0.8381\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0641 - accuracy: 0.9751 - val_loss: 0.5554 - val_accuracy: 0.8746\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0695 - accuracy: 0.9776 - val_loss: 0.5033 - val_accuracy: 0.8592\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0419 - accuracy: 0.9856 - val_loss: 0.5615 - val_accuracy: 0.8754\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0410 - accuracy: 0.9851 - val_loss: 0.5564 - val_accuracy: 0.8503\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.4998 - val_accuracy: 0.8704\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.5414 - val_accuracy: 0.8607\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.6176 - val_accuracy: 0.8750\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.7889 - val_accuracy: 0.8432\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.6188 - val_accuracy: 0.8350\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.6565 - val_accuracy: 0.8576\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.6083 - val_accuracy: 0.8656\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.6216 - val_accuracy: 0.8446\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0819 - accuracy: 0.9719 - val_loss: 0.5892 - val_accuracy: 0.8310\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0598 - accuracy: 0.9798 - val_loss: 0.5217 - val_accuracy: 0.8689\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 0.5879 - val_accuracy: 0.8714\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0435 - accuracy: 0.9845 - val_loss: 0.6199 - val_accuracy: 0.8600\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.6218 - val_accuracy: 0.8597\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 0.8049 - val_accuracy: 0.8238\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0673 - accuracy: 0.9755 - val_loss: 0.5246 - val_accuracy: 0.8543\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.5554 - val_accuracy: 0.8674\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 0.6402 - val_accuracy: 0.8568\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.5812 - val_accuracy: 0.8435\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.5981 - val_accuracy: 0.8558\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0640 - accuracy: 0.9771 - val_loss: 0.6114 - val_accuracy: 0.8388\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0620 - accuracy: 0.9769 - val_loss: 0.5809 - val_accuracy: 0.8449\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0577 - accuracy: 0.9824 - val_loss: 0.6063 - val_accuracy: 0.8571\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.5377 - val_accuracy: 0.8612\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.5503 - val_accuracy: 0.8784\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.5374 - val_accuracy: 0.8796\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0590 - accuracy: 0.9798 - val_loss: 0.5524 - val_accuracy: 0.8241\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1008 - accuracy: 0.9633 - val_loss: 0.5567 - val_accuracy: 0.8481\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.5696 - val_accuracy: 0.8324\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0611 - accuracy: 0.9787 - val_loss: 0.5723 - val_accuracy: 0.8567\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.5679 - val_accuracy: 0.8689\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.6603 - val_accuracy: 0.8421\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 0.6041 - val_accuracy: 0.8564\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0428 - accuracy: 0.9845 - val_loss: 0.6939 - val_accuracy: 0.8067\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.5743 - val_accuracy: 0.8573\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.5876 - val_accuracy: 0.8557\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.5855 - val_accuracy: 0.8406\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0675 - accuracy: 0.9737 - val_loss: 0.7260 - val_accuracy: 0.8165\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0570 - accuracy: 0.9779 - val_loss: 0.5765 - val_accuracy: 0.8493\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0428 - accuracy: 0.9833 - val_loss: 0.5885 - val_accuracy: 0.8680\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.6968 - val_accuracy: 0.8591\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 0.7296 - val_accuracy: 0.8403\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.5367 - val_accuracy: 0.8658\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.5969 - val_accuracy: 0.8624\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.5518 - val_accuracy: 0.8717\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.5314 - val_accuracy: 0.8869\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.5575 - val_accuracy: 0.8753\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0447 - accuracy: 0.9866 - val_loss: 0.5888 - val_accuracy: 0.8644\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.5858 - val_accuracy: 0.8738\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.5225 - val_accuracy: 0.8732\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.5812 - val_accuracy: 0.8682\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0751 - accuracy: 0.9741 - val_loss: 0.5712 - val_accuracy: 0.8579\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0681 - accuracy: 0.9730 - val_loss: 0.4254 - val_accuracy: 0.8734\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.5644 - val_accuracy: 0.8629\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0769 - accuracy: 0.9707 - val_loss: 0.5187 - val_accuracy: 0.8555\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.5300 - val_accuracy: 0.8329\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0608 - accuracy: 0.9750 - val_loss: 0.6476 - val_accuracy: 0.8391\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0602 - accuracy: 0.9799 - val_loss: 0.5164 - val_accuracy: 0.8679\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 0.6276 - val_accuracy: 0.8491\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0636 - accuracy: 0.9782 - val_loss: 0.6268 - val_accuracy: 0.8506\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.5877 - val_accuracy: 0.8719\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.5399 - val_accuracy: 0.8762\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.5716 - val_accuracy: 0.8516\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.4851 - val_accuracy: 0.8780\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.6122 - val_accuracy: 0.8603\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.4130 - val_accuracy: 0.8902\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.5597 - val_accuracy: 0.8747\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0568 - accuracy: 0.9813 - val_loss: 0.4216 - val_accuracy: 0.8749\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0566 - accuracy: 0.9775 - val_loss: 0.5444 - val_accuracy: 0.8749\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0677 - accuracy: 0.9733 - val_loss: 0.5787 - val_accuracy: 0.8586\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.6574 - val_accuracy: 0.8585\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0454 - accuracy: 0.9826 - val_loss: 0.7154 - val_accuracy: 0.8241\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.5779 - val_accuracy: 0.8687\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.5229 - val_accuracy: 0.8665\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.5593 - val_accuracy: 0.8589\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0794 - accuracy: 0.9705 - val_loss: 0.6155 - val_accuracy: 0.8180\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0777 - accuracy: 0.9729 - val_loss: 0.6421 - val_accuracy: 0.8400\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.5401 - val_accuracy: 0.8635\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0625 - accuracy: 0.9764 - val_loss: 0.5967 - val_accuracy: 0.8473\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0545 - accuracy: 0.9826 - val_loss: 0.5673 - val_accuracy: 0.8625\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 0.5413 - val_accuracy: 0.8738\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 0.5822 - val_accuracy: 0.8499\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0653 - accuracy: 0.9743 - val_loss: 0.5546 - val_accuracy: 0.8473\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0480 - accuracy: 0.9835 - val_loss: 0.6511 - val_accuracy: 0.8687\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 0.8179 - val_accuracy: 0.7612\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1090 - accuracy: 0.9601 - val_loss: 0.5525 - val_accuracy: 0.8330\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.1308 - accuracy: 0.9542 - val_loss: 0.5223 - val_accuracy: 0.8467\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0708 - accuracy: 0.9753 - val_loss: 0.7230 - val_accuracy: 0.8223\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0937 - accuracy: 0.9654 - val_loss: 0.5760 - val_accuracy: 0.8629\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0841 - accuracy: 0.9691 - val_loss: 0.6230 - val_accuracy: 0.8260\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0891 - accuracy: 0.9669 - val_loss: 0.5027 - val_accuracy: 0.8671\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.4130 - val_accuracy: 0.8838\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.4645 - val_accuracy: 0.8749\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0558 - accuracy: 0.9829 - val_loss: 0.5236 - val_accuracy: 0.8701\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0490 - accuracy: 0.9809 - val_loss: 0.5802 - val_accuracy: 0.8537\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0940 - accuracy: 0.9651 - val_loss: 0.4817 - val_accuracy: 0.8626\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0572 - accuracy: 0.9760 - val_loss: 0.5539 - val_accuracy: 0.8558\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1026 - accuracy: 0.9601 - val_loss: 0.5090 - val_accuracy: 0.8512\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0800 - accuracy: 0.9718 - val_loss: 0.4583 - val_accuracy: 0.8350\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.4708 - val_accuracy: 0.8632\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.3986 - val_accuracy: 0.8884\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.3832 - val_accuracy: 0.8522\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0902 - accuracy: 0.9688 - val_loss: 0.4063 - val_accuracy: 0.8737\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0428 - accuracy: 0.9850 - val_loss: 0.5238 - val_accuracy: 0.8662\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0382 - accuracy: 0.9865 - val_loss: 0.5106 - val_accuracy: 0.8637\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 0.5272 - val_accuracy: 0.8705\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0461 - accuracy: 0.9821 - val_loss: 0.5568 - val_accuracy: 0.8458\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0534 - accuracy: 0.9799 - val_loss: 0.4823 - val_accuracy: 0.8813\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0338 - accuracy: 0.9871 - val_loss: 0.5443 - val_accuracy: 0.8690\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.4787 - val_accuracy: 0.8625\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 0.4190 - val_accuracy: 0.8737\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.4713 - val_accuracy: 0.8686\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0666 - accuracy: 0.9757 - val_loss: 0.3824 - val_accuracy: 0.8933\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0662 - accuracy: 0.9756 - val_loss: 0.4011 - val_accuracy: 0.8699\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.4520 - val_accuracy: 0.8945\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.5270 - val_accuracy: 0.8787\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0353 - accuracy: 0.9858 - val_loss: 0.6343 - val_accuracy: 0.8555\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.4357 - val_accuracy: 0.8914\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0386 - accuracy: 0.9851 - val_loss: 0.5039 - val_accuracy: 0.8625\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.5413 - val_accuracy: 0.8795\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 0.5977 - val_accuracy: 0.8382\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.5844 - val_accuracy: 0.8524\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.4504 - val_accuracy: 0.8874\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.4817 - val_accuracy: 0.8854\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 0.5112 - val_accuracy: 0.8876\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 0.4305 - val_accuracy: 0.8836\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0490 - accuracy: 0.9814 - val_loss: 0.4522 - val_accuracy: 0.8524\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0728 - accuracy: 0.9746 - val_loss: 0.4496 - val_accuracy: 0.8671\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.6430 - val_accuracy: 0.8632\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.6026 - val_accuracy: 0.8671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmdeEi74Nf6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c441abc8-5a13-46f8-fee7-b47f7686fcc5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.plot(history1.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,1.2])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Bd3MkKAKilNH",
        "outputId": "1bc5e41f-35bc-4050-93de-22abee69c7a7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,1.2])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XOStp3_io_U",
        "outputId": "02e7c3bd-246a-4be5-f0b9-3ab9ae905c18"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history3.history['loss'])\n",
        "plt.plot(history3.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,1.2])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "km6o9kCBiqHb",
        "outputId": "7f9f4550-784d-4f5a-dcc0-69f593681d84"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history4.history['loss'])\n",
        "plt.plot(history4.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,1.2])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQTiAkDEy_pQ"
      },
      "source": [
        "pred1 = model1.predict(Xval)\n",
        "pred2 = model2.predict(Xval)\n",
        "pred3 = model3.predict(Xval)\n",
        "pred4 = model4.predict(Xval)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_lD1UX6g3Bj"
      },
      "source": [
        "predicted_class1 = pred1.flatten()\n",
        "predicted_class2 = pred2.flatten()\n",
        "predicted_class3 = pred3.flatten()\n",
        "predicted_class4 = pred4.flatten()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oR3oQzHz5kD"
      },
      "source": [
        "total_predicted = (0.25 * predicted_class1) + (0.25 * predicted_class2) + (0.25 * predicted_class3) + (0.25 * predicted_class4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTpDS2PHi2BA"
      },
      "source": [
        "total_predicted[total_predicted >= 0.5] = 1\n",
        "total_predicted[total_predicted < 0.5] = 0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-EgDoAZitx7"
      },
      "source": [
        "predicted_class1[predicted_class1 >= 0.5] = 1\n",
        "predicted_class1[predicted_class1 < 0.5] = 0\n",
        "\n",
        "predicted_class2[predicted_class2 >= 0.5] = 1\n",
        "predicted_class2[predicted_class2 < 0.5] = 0\n",
        "\n",
        "predicted_class3[predicted_class3 >= 0.5] = 1\n",
        "predicted_class3[predicted_class3 < 0.5] = 0\n",
        "\n",
        "predicted_class4[predicted_class4 >= 0.5] = 1\n",
        "predicted_class4[predicted_class4 < 0.5] = 0\n",
        "\n",
        "true = Yval.flatten()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlrFocq6jBSe",
        "outputId": "8363ac8d-d36d-478b-e705-57629c2e226e"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Model 1 prediction accuracy:\", sklearn.metrics.accuracy_score(predicted_class1, true))\n",
        "print(\"Model 2 prediction accuracy:\", sklearn.metrics.accuracy_score(predicted_class2, true))\n",
        "print(\"Model 3 prediction accuracy:\", sklearn.metrics.accuracy_score(predicted_class3, true))\n",
        "print(\"Model 4 prediction accuracy:\", sklearn.metrics.accuracy_score(predicted_class4, true))\n",
        "print(\"Ensemble prediction accuracy:\", sklearn.metrics.accuracy_score(total_predicted, true))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 prediction accuracy: 0.9095238095238095\n",
            "Model 2 prediction accuracy: 0.8986607142857143\n",
            "Model 3 prediction accuracy: 0.8787202380952381\n",
            "Model 4 prediction accuracy: 0.8671130952380952\n",
            "Ensemble prediction accuracy: 0.9151785714285714\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}